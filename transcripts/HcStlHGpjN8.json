[{"text": "so I'm going to tell you a very not", "start": 0.03, "duration": 8.159}, {"text": "super deep into any one topic but very", "start": 6.029, "duration": 5.161}, {"text": "broad brush sense of the kinds of things", "start": 8.189, "duration": 4.441}, {"text": "we've been using deep learning for the", "start": 11.19, "duration": 3.18}, {"text": "kinds of systems we've built around", "start": 12.63, "duration": 5.31}, {"text": "making deep learning faster and this is", "start": 14.37, "duration": 6.06}, {"text": "joint work with many many many people at", "start": 17.94, "duration": 5.429}, {"text": "Google so this is not purely my work but", "start": 20.43, "duration": 5.009}, {"text": "most of it is from the Google brain team", "start": 23.369, "duration": 6.211}, {"text": "which I lead and so the brain teams", "start": 25.439, "duration": 5.731}, {"text": "mission is basically makes machines", "start": 29.58, "duration": 3.659}, {"text": "intelligent and then use that new", "start": 31.17, "duration": 4.26}, {"text": "capability to improve people's lives in", "start": 33.239, "duration": 5.191}, {"text": "a number of different ways and the way", "start": 35.43, "duration": 5.37}, {"text": "we do this is we conduct a long-term", "start": 38.43, "duration": 4.11}, {"text": "research kind of independent of any", "start": 40.8, "duration": 4.65}, {"text": "particular application in of and", "start": 42.54, "duration": 5.69}, {"text": "probably supposed to stand in one place", "start": 45.45, "duration": 5.57}, {"text": "independent of any particular", "start": 48.23, "duration": 7.5}, {"text": "application we build an open-source", "start": 51.02, "duration": 6.94}, {"text": "systems that help us with our research", "start": 55.73, "duration": 4.44}, {"text": "and deploying of machine learning models", "start": 57.96, "duration": 4.16}, {"text": "like tensorflow", "start": 60.17, "duration": 5.319}, {"text": "we collaborate across Google and all of", "start": 62.12, "duration": 5.77}, {"text": "alphabet in getting machine learning", "start": 65.489, "duration": 4.681}, {"text": "systems and research that we've done", "start": 67.89, "duration": 4.53}, {"text": "into real Google products so we've done", "start": 70.17, "duration": 4.41}, {"text": "a lot of work in like Google search", "start": 72.42, "duration": 4.68}, {"text": "Gmail photos speech recognition", "start": 74.58, "duration": 5.51}, {"text": "translate and you know many other places", "start": 77.1, "duration": 5.519}, {"text": "we also bring in a lot of people into", "start": 80.09, "duration": 5.41}, {"text": "our group through internships and a new", "start": 82.619, "duration": 4.411}, {"text": "residency program that we started last", "start": 85.5, "duration": 3.509}, {"text": "year for people who want to learn how to", "start": 87.03, "duration": 4.62}, {"text": "do deep learning research and that's", "start": 89.009, "duration": 4.081}, {"text": "going to pretty successful program as", "start": 91.65, "duration": 4.92}, {"text": "well so the main research area is that", "start": 93.09, "duration": 6.45}, {"text": "our group is working in are these I'm", "start": 96.57, "duration": 6.06}, {"text": "going to focus mostly on these today", "start": 99.54, "duration": 5.66}, {"text": "actually a little bit of perception too", "start": 102.63, "duration": 8.46}, {"text": "but so in January I put out a blog post", "start": 105.2, "duration": 7.419}, {"text": "that kind of just highlighted some of", "start": 111.09, "duration": 3.33}, {"text": "the work our group has done over the", "start": 112.619, "duration": 4.471}, {"text": "last over 2016 and in putting that", "start": 114.42, "duration": 4.08}, {"text": "together I kind of realized we were", "start": 117.09, "duration": 4.05}, {"text": "doing a lot of different things so the", "start": 118.5, "duration": 4.5}, {"text": "nice thing about this is each one of", "start": 121.14, "duration": 4.5}, {"text": "these blue links is a link to something", "start": 123.0, "duration": 4.35}, {"text": "kind of interesting and substantial like", "start": 125.64, "duration": 4.14}, {"text": "a research paper or a product launch", "start": 127.35, "duration": 3.79}, {"text": "using", "start": 129.78, "duration": 5.59}, {"text": "learning or some new tensorflow features", "start": 131.14, "duration": 7.77}, {"text": "we've we've added so I won't go through", "start": 135.37, "duration": 5.25}, {"text": "that all now but you can go find that", "start": 138.91, "duration": 4.62}, {"text": "blog post and learn more about some of", "start": 140.62, "duration": 5.76}, {"text": "the stuff we've done up to okay so why", "start": 143.53, "duration": 4.26}, {"text": "are we here you probably already all", "start": 146.38, "duration": 2.94}, {"text": "know this given that you're working on", "start": 147.79, "duration": 3.71}, {"text": "AI related companies as I understand it", "start": 149.32, "duration": 7.23}, {"text": "but the field of deep learning and", "start": 151.5, "duration": 6.48}, {"text": "neural networks in particular are really", "start": 156.55, "duration": 4.5}, {"text": "causing a shift in how we think about", "start": 157.98, "duration": 5.38}, {"text": "approaching a lot of problems and I", "start": 161.05, "duration": 4.439}, {"text": "think it's really changing the kinds of", "start": 163.36, "duration": 3.39}, {"text": "machine learning approaches that we use", "start": 165.489, "duration": 4.071}, {"text": "in the 80s and 90s it was the case that", "start": 166.75, "duration": 4.89}, {"text": "neural Nets seemed interesting and", "start": 169.56, "duration": 4.75}, {"text": "appealing but they weren't the best", "start": 171.64, "duration": 6.24}, {"text": "solution at the time for a lot of", "start": 174.31, "duration": 5.429}, {"text": "problems we cared about because they", "start": 177.88, "duration": 4.32}, {"text": "just didn't quite have enough training", "start": 179.739, "duration": 5.241}, {"text": "data enough computational capabilities", "start": 182.2, "duration": 5.55}, {"text": "and so people used other methods or", "start": 184.98, "duration": 4.96}, {"text": "developed kind of shallower machine", "start": 187.75, "duration": 3.72}, {"text": "learning methods with much more hand", "start": 189.94, "duration": 4.11}, {"text": "engineering your futures and if you fast", "start": 191.47, "duration": 4.14}, {"text": "forward to now what's happened is we've", "start": 194.05, "duration": 3.3}, {"text": "got much much more compute I actually", "start": 195.61, "duration": 5.67}, {"text": "did an undergrad thesis in 1990 on", "start": 197.35, "duration": 5.37}, {"text": "parallel training of neural labs because", "start": 201.28, "duration": 4.019}, {"text": "I liked appealing attraction of the", "start": 202.72, "duration": 4.65}, {"text": "neural net model and I thought if we", "start": 205.299, "duration": 4.021}, {"text": "could just get like you know a bunch", "start": 207.37, "duration": 4.679}, {"text": "more compute by paralyzing over a you", "start": 209.32, "duration": 4.83}, {"text": "know a 64 processor hypercube machine", "start": 212.049, "duration": 4.711}, {"text": "that it would all be even better it", "start": 214.15, "duration": 3.96}, {"text": "turned out what we needed was like a", "start": 216.76, "duration": 2.729}, {"text": "hundred thousand times as much compute", "start": 218.11, "duration": 3.99}, {"text": "not sixty times but if you fast forward", "start": 219.489, "duration": 5.431}, {"text": "to today we actually have that and so", "start": 222.1, "duration": 6.08}, {"text": "what's happened is we now actually have", "start": 224.92, "duration": 6.18}, {"text": "you know the case where neural apps are", "start": 228.18, "duration": 4.809}, {"text": "the best solution for an awful lot of", "start": 231.1, "duration": 3.84}, {"text": "problems and a growing set of problems", "start": 232.989, "duration": 5.161}, {"text": "where we either previously didn't really", "start": 234.94, "duration": 5.28}, {"text": "know how to solve the problem or where", "start": 238.15, "duration": 3.929}, {"text": "we could solve it but now we can solve", "start": 240.22, "duration": 4.049}, {"text": "it better with known apps so the talk is", "start": 242.079, "duration": 6.0}, {"text": "really meant to orient you across a", "start": 244.269, "duration": 5.28}, {"text": "whole bunch of different problems where", "start": 248.079, "duration": 4.861}, {"text": "this is the case so growing use of deep", "start": 249.549, "duration": 6.421}, {"text": "learning so really our group started in", "start": 252.94, "duration": 4.919}, {"text": "order to investigate the hypothesis that", "start": 255.97, "duration": 4.29}, {"text": "large amounts of compute could actually", "start": 257.859, "duration": 5.791}, {"text": "solve interesting problems using your", "start": 260.26, "duration": 3.96}, {"text": "labs", "start": 263.65, "duration": 2.85}, {"text": "and so when we first started you know", "start": 264.22, "duration": 3.89}, {"text": "they weren't we were sort of the", "start": 266.5, "duration": 4.29}, {"text": "vanguard of people using no labs at", "start": 268.11, "duration": 4.72}, {"text": "Google we did a bunch of work on", "start": 270.79, "duration": 5.13}, {"text": "unsupervised learning at a really large", "start": 272.83, "duration": 5.76}, {"text": "scale using at that time we didn't even", "start": 275.92, "duration": 4.26}, {"text": "have GPUs in our data centers so we just", "start": 278.59, "duration": 4.5}, {"text": "used 16,000 GPU cores and we did kind of", "start": 280.18, "duration": 4.62}, {"text": "interesting things with unsupervised", "start": 283.09, "duration": 4.53}, {"text": "learning there but gradually we kind of", "start": 284.8, "duration": 4.98}, {"text": "built tools that enable people to use", "start": 287.62, "duration": 3.99}, {"text": "fly machine learning and deep learning", "start": 289.78, "duration": 4.05}, {"text": "in particular to a lot of problems and", "start": 291.61, "duration": 5.13}, {"text": "you can see the growth rate of you know", "start": 293.83, "duration": 4.59}, {"text": "this is directories containing model", "start": 296.74, "duration": 3.24}, {"text": "description files either from our first", "start": 298.42, "duration": 5.3}, {"text": "generation system and starting in about", "start": 299.98, "duration": 6.45}, {"text": "2015 our second generation system", "start": 303.72, "duration": 5.8}, {"text": "tensorflow and we've deployed machine", "start": 306.43, "duration": 4.68}, {"text": "learning and in collaboration with lots", "start": 309.52, "duration": 3.33}, {"text": "of teams other teams have also been", "start": 311.11, "duration": 4.5}, {"text": "independently just picking up this idea", "start": 312.85, "duration": 4.26}, {"text": "of deep learning and using in lots and", "start": 315.61, "duration": 3.11}, {"text": "lots of places in Google products and", "start": 317.11, "duration": 4.02}, {"text": "that's why you see that growth rate and", "start": 318.72, "duration": 7.06}, {"text": "it's continuing to go out one of the", "start": 321.13, "duration": 6.99}, {"text": "things we focus on a lot is how can we", "start": 325.78, "duration": 4.29}, {"text": "reduce experimental turnaround time for", "start": 328.12, "duration": 4.56}, {"text": "our machine learning experiment and", "start": 330.07, "duration": 4.77}, {"text": "because there's a very different", "start": 332.68, "duration": 5.489}, {"text": "qualitative feel to doing science and", "start": 334.84, "duration": 5.67}, {"text": "research in a domain where an experiment", "start": 338.169, "duration": 4.741}, {"text": "takes a month versus doing it in a", "start": 340.51, "duration": 4.5}, {"text": "domain where you know minutes or hours", "start": 342.91, "duration": 4.77}, {"text": "you get you know an answer and then you", "start": 345.01, "duration": 3.81}, {"text": "can figure out what the next set of", "start": 347.68, "duration": 3.03}, {"text": "experiments are that you want to run so", "start": 348.82, "duration": 4.65}, {"text": "a lot of our focus is on scaling machine", "start": 350.71, "duration": 4.26}, {"text": "learning models and scaling the", "start": 353.47, "duration": 3.3}, {"text": "underlying infrastructure and systems so", "start": 354.97, "duration": 4.29}, {"text": "that we can actually for some problems", "start": 356.77, "duration": 5.18}, {"text": "approach minutes or hours rather than", "start": 359.26, "duration": 6.99}, {"text": "weeks or months so part of that has been", "start": 361.95, "duration": 6.25}, {"text": "building the right tools so tensorflow", "start": 366.25, "duration": 4.44}, {"text": "is kind of our second generation system", "start": 368.2, "duration": 4.65}, {"text": "that we built for tackling deep learning", "start": 370.69, "duration": 3.68}, {"text": "problems and machine learning problems", "start": 372.85, "duration": 3.96}, {"text": "the first one we did an open-source the", "start": 374.37, "duration": 5.799}, {"text": "second one we said we should really fix", "start": 376.81, "duration": 5.28}, {"text": "some of the design problems we saw on", "start": 380.169, "duration": 3.781}, {"text": "our first system keep the good features", "start": 382.09, "duration": 4.77}, {"text": "about it and then design this from the", "start": 383.95, "duration": 5.46}, {"text": "start to be an open source platform so", "start": 386.86, "duration": 4.65}, {"text": "that people all over the world not just", "start": 389.41, "duration": 5.22}, {"text": "at Google can benefit from from this and", "start": 391.51, "duration": 5.739}, {"text": "can help build a community that can all", "start": 394.63, "duration": 5.889}, {"text": "contribute to and improve the system Zac", "start": 397.249, "duration": 3.81}, {"text": "stoned", "start": 400.519, "duration": 4.29}, {"text": "here is our tensorflow product manager", "start": 401.059, "duration": 8.25}, {"text": "extraordinaire and is doing a great job", "start": 404.809, "duration": 6.15}, {"text": "of building the community building", "start": 409.309, "duration": 5.82}, {"text": "inside Google and outside so the goals", "start": 410.959, "duration": 5.01}, {"text": "of tensorflow", "start": 415.129, "duration": 2.79}, {"text": "that we want to establish this common", "start": 415.969, "duration": 4.5}, {"text": "platform for expressing all kinds of", "start": 417.919, "duration": 4.17}, {"text": "machine learning ideas so something that", "start": 420.469, "duration": 3.42}, {"text": "can be used for deep learning can be", "start": 422.089, "duration": 2.85}, {"text": "used for other kinds of machine learning", "start": 423.889, "duration": 3.3}, {"text": "that can be used for tackling perception", "start": 424.939, "duration": 4.5}, {"text": "problems and you know language", "start": 427.189, "duration": 4.95}, {"text": "understanding problems and what if you", "start": 429.439, "duration": 4.65}, {"text": "have a crazy new machine learning", "start": 432.139, "duration": 3.69}, {"text": "research idea that doesn't really fit", "start": 434.089, "duration": 4.08}, {"text": "into what people have done before we", "start": 435.829, "duration": 3.93}, {"text": "want it to be at least expressible", "start": 438.169, "duration": 3.65}, {"text": "relatively easily in tensorflow", "start": 439.759, "duration": 5.64}, {"text": "and then we want to make that platform", "start": 441.819, "duration": 5.08}, {"text": "really great for research but we also", "start": 445.399, "duration": 5.67}, {"text": "want to be able to take that something", "start": 446.899, "duration": 5.52}, {"text": "you've developed in tensorflow maybe", "start": 451.069, "duration": 3.69}, {"text": "experimentally and then if you now want", "start": 452.419, "duration": 3.66}, {"text": "to deploy that in a production setting", "start": 454.759, "duration": 3.09}, {"text": "run it at the data center run it at", "start": 456.079, "duration": 4.74}, {"text": "scale running on a phone all these kinds", "start": 457.849, "duration": 6.59}, {"text": "of things we want that to be another", "start": 460.819, "duration": 6.63}, {"text": "something you can do in the sense of a", "start": 464.439, "duration": 5.32}, {"text": "framework and by open sourcing it we", "start": 467.449, "duration": 6.42}, {"text": "make it available to everyone so how has", "start": 469.759, "duration": 8.28}, {"text": "this been going well so this is a", "start": 473.869, "duration": 7.44}, {"text": "comparison of github stars of which is", "start": 478.039, "duration": 5.52}, {"text": "one metric of popularity or interest in", "start": 481.309, "duration": 4.65}, {"text": "different source code repositories on", "start": 483.559, "duration": 5.61}, {"text": "github and I show you a comparison of", "start": 485.959, "duration": 4.59}, {"text": "tensorflow with a bunch of other", "start": 489.169, "duration": 3.47}, {"text": "open-source machine learning packages", "start": 490.549, "duration": 4.5}, {"text": "many of which have been around for for", "start": 492.639, "duration": 4.93}, {"text": "you know many more years of intensive", "start": 495.049, "duration": 5.1}, {"text": "attention flows this brown line up going", "start": 497.569, "duration": 5.34}, {"text": "up fairly steeply so this has been", "start": 500.149, "duration": 4.65}, {"text": "pretty good I think the the reception", "start": 502.909, "duration": 4.59}, {"text": "for what tensorflow does which is enable", "start": 504.799, "duration": 5.37}, {"text": "flexible research but also this kind of", "start": 507.499, "duration": 5.16}, {"text": "production readiness and being able to", "start": 510.169, "duration": 4.8}, {"text": "run in lots of places is pretty", "start": 512.659, "duration": 5.28}, {"text": "appealing and if you look at the other", "start": 514.969, "duration": 4.891}, {"text": "open source packages which we did when", "start": 517.939, "duration": 3.33}, {"text": "we were starting to work on tensorflow", "start": 519.86, "duration": 4.169}, {"text": "you know many of them have two of the", "start": 521.269, "duration": 4.17}, {"text": "three attributes that we care about", "start": 524.029, "duration": 3.141}, {"text": "being able to be really flexible", "start": 525.439, "duration": 3.881}, {"text": "scalable and", "start": 527.17, "duration": 5.3}, {"text": "sort of run on any platform and they all", "start": 529.32, "duration": 5.25}, {"text": "have different emphases but we wanted", "start": 532.47, "duration": 3.72}, {"text": "something that satisfied all three of", "start": 534.57, "duration": 5.67}, {"text": "those so that's kind of cool we've been", "start": 536.19, "duration": 6.66}, {"text": "focusing a fair amount on speed I think", "start": 540.24, "duration": 4.71}, {"text": "when we first released tensorflow we", "start": 542.85, "duration": 3.18}, {"text": "released a bunch of really nice", "start": 544.95, "duration": 3.78}, {"text": "tutorials that showed how to do", "start": 546.03, "duration": 3.93}, {"text": "different things with tensorflow", "start": 548.73, "duration": 3.45}, {"text": "but one of the mistakes we made was we", "start": 549.96, "duration": 4.74}, {"text": "released code that was meant to be", "start": 552.18, "duration": 5.79}, {"text": "exposed Tory and clear and not", "start": 554.7, "duration": 5.07}, {"text": "necessarily the highest performance way", "start": 557.97, "duration": 4.35}, {"text": "you would write that but often then", "start": 559.77, "duration": 4.41}, {"text": "people would take that as the way you", "start": 562.32, "duration": 2.97}, {"text": "should write a high performance", "start": 564.18, "duration": 2.91}, {"text": "tensorflow model and that wasn't", "start": 565.29, "duration": 4.38}, {"text": "necessarily a case so we're now adapting", "start": 567.09, "duration": 4.65}, {"text": "and trying to put out things that are", "start": 569.67, "duration": 4.86}, {"text": "both the best way from a clarity", "start": 571.74, "duration": 4.67}, {"text": "standpoint but also our high performance", "start": 574.53, "duration": 6.63}, {"text": "that's been a bit of a tentacle guide I", "start": 576.41, "duration": 6.37}, {"text": "think a bit of a bad rap but actually", "start": 581.16, "duration": 3.24}, {"text": "our performance is quite good so we've", "start": 582.78, "duration": 5.43}, {"text": "been doing a bunch of benchmarking and", "start": 584.4, "duration": 5.85}, {"text": "producing reproducible benchmark results", "start": 588.21, "duration": 3.27}, {"text": "that shows that our scaling is quite", "start": 590.25, "duration": 3.21}, {"text": "good so this is single machine scaling", "start": 591.48, "duration": 5.31}, {"text": "nearly linear speed-up for a bunch of", "start": 593.46, "duration": 6.9}, {"text": "different image models on up to 8 GPU", "start": 596.79, "duration": 6.24}, {"text": "cards pretty close to linear speed-up", "start": 600.36, "duration": 5.97}, {"text": "for 64 GPU cards for a bunch of", "start": 603.03, "duration": 7.59}, {"text": "different kinds of problems so don't", "start": 606.33, "duration": 6.51}, {"text": "don't if you hear tensorflow slow don't", "start": 610.62, "duration": 4.82}, {"text": "don't believe it", "start": 612.84, "duration": 2.6}, {"text": "we also support lots of different", "start": 615.53, "duration": 4.15}, {"text": "platforms and I think this is important", "start": 618.21, "duration": 4.41}, {"text": "because often you want to train a model", "start": 619.68, "duration": 4.74}, {"text": "on a large data set in a data center but", "start": 622.62, "duration": 3.84}, {"text": "then deploy that on a phone and so we", "start": 624.42, "duration": 4.41}, {"text": "run on you know iOS and Android and", "start": 626.46, "duration": 6.72}, {"text": "raspberry PI's but also CPUs and if you", "start": 628.83, "duration": 6.39}, {"text": "have a GPU card or a TV you cards we're", "start": 633.18, "duration": 4.77}, {"text": "happy to use that we also run on our", "start": 635.22, "duration": 4.41}, {"text": "custom machine learning accelerators", "start": 637.95, "duration": 3.9}, {"text": "that I'll talk about in a minute but", "start": 639.63, "duration": 3.69}, {"text": "really we want to run on everything so", "start": 641.85, "duration": 2.49}, {"text": "there's a bunch of other device", "start": 643.32, "duration": 3.33}, {"text": "manufacturers that are developing kind", "start": 644.34, "duration": 5.25}, {"text": "of funky mobile ml accelerators or", "start": 646.65, "duration": 5.85}, {"text": "Qualcomm has a DSP and they're all", "start": 649.59, "duration": 4.71}, {"text": "working to make sure the tempter flow", "start": 652.5, "duration": 4.28}, {"text": "runs well on those devices", "start": 654.3, "duration": 5.31}, {"text": "we also kind of want to be agnostic of", "start": 656.78, "duration": 6.28}, {"text": "language that people want because you", "start": 659.61, "duration": 5.1}, {"text": "want to be able to run machine learning", "start": 663.06, "duration": 3.6}, {"text": "where it makes sense and different", "start": 664.71, "duration": 3.57}, {"text": "people have different sort of language", "start": 666.66, "duration": 3.54}, {"text": "environments most the most fully", "start": 668.28, "duration": 5.88}, {"text": "developed system is obviously Python but", "start": 670.2, "duration": 5.94}, {"text": "the C++ friend works pretty well for", "start": 674.16, "duration": 4.41}, {"text": "production use and then a bunch of other", "start": 676.14, "duration": 4.38}, {"text": "people of external community members", "start": 678.57, "duration": 4.59}, {"text": "have added a variety of other kind of", "start": 680.52, "duration": 5.13}, {"text": "not fully fleshed out but reasonable", "start": 683.16, "duration": 3.6}, {"text": "support for some of these other", "start": 685.65, "duration": 5.85}, {"text": "languages we have a pretty broad usage", "start": 686.76, "duration": 8.07}, {"text": "base so like a year ago we had a almost", "start": 691.5, "duration": 6.57}, {"text": "a year ago we had a meeting at Google of", "start": 694.83, "duration": 5.94}, {"text": "people using tensorflow and it was", "start": 698.07, "duration": 4.1}, {"text": "pretty impressive we had people from", "start": 700.77, "duration": 3.69}, {"text": "most of these companies in the room", "start": 702.17, "duration": 3.97}, {"text": "which I think normally they don't all", "start": 704.46, "duration": 4.59}, {"text": "get in a room together places like Apple", "start": 706.14, "duration": 4.23}, {"text": "is actually there as well and Vidya", "start": 709.05, "duration": 5.25}, {"text": "Qualcomm uber Google snapchat you know", "start": 710.37, "duration": 9.2}, {"text": "many men until many many other places so", "start": 714.3, "duration": 8.16}, {"text": "terms of stars you know I showed you the", "start": 719.57, "duration": 4.21}, {"text": "graphs related to machine learning", "start": 722.46, "duration": 5.79}, {"text": "platforms this is the top repositories", "start": 723.78, "duration": 6.81}, {"text": "on github overall and we're up to number", "start": 728.25, "duration": 5.58}, {"text": "six which is pretty good and all the", "start": 730.59, "duration": 4.83}, {"text": "other ones are either Java Script or a", "start": 733.83, "duration": 7.28}, {"text": "list of programming books this is a", "start": 735.42, "duration": 8.01}, {"text": "visualization of where people are", "start": 741.11, "duration": 3.58}, {"text": "interested in different github", "start": 743.43, "duration": 3.8}, {"text": "repositories which is kind of cool", "start": 744.69, "duration": 4.53}, {"text": "machine learning is done all over the", "start": 747.23, "duration": 9.07}, {"text": "world so one of the things that's", "start": 749.22, "duration": 9.12}, {"text": "happened as that growth in interest has", "start": 756.3, "duration": 5.28}, {"text": "happened is there's been a pretty broad", "start": 758.34, "duration": 6.09}, {"text": "set of external control contributors and", "start": 761.58, "duration": 4.41}, {"text": "so there's really you know I think we're", "start": 764.43, "duration": 3.26}, {"text": "up to almost a thousand non-google", "start": 765.99, "duration": 4.71}, {"text": "contributors across the world doing all", "start": 767.69, "duration": 5.59}, {"text": "kinds of different things for adding", "start": 770.7, "duration": 4.71}, {"text": "features or fixing bugs or improving the", "start": 773.28, "duration": 3.75}, {"text": "system in various ways which is been", "start": 775.41, "duration": 2.22}, {"text": "really nice", "start": 777.03, "duration": 3.63}, {"text": "oh and I think it's kind of nice that", "start": 777.63, "duration": 4.65}, {"text": "there's growing use in machine learning", "start": 780.66, "duration": 3.81}, {"text": "classes of tensorflow as a way of", "start": 782.28, "duration": 3.9}, {"text": "illustrating machine learning concepts", "start": 784.47, "duration": 4.5}, {"text": "so at really good machine learning", "start": 786.18, "duration": 3.42}, {"text": "University", "start": 788.97, "duration": 2.19}, {"text": "like Toronto Berkeley Stanford in other", "start": 789.6, "duration": 3.539}, {"text": "places they're starting to use that as", "start": 791.16, "duration": 7.71}, {"text": "the core of their curriculum okay so now", "start": 793.139, "duration": 6.991}, {"text": "I'm going to switch gears a bit and talk", "start": 798.87, "duration": 3.329}, {"text": "about some sort of more product oriented", "start": 800.13, "duration": 3.889}, {"text": "applications of deep learning at Google", "start": 802.199, "duration": 3.961}, {"text": "Google photos is a good example", "start": 804.019, "duration": 4.331}, {"text": "obviously computer vision that works and", "start": 806.16, "duration": 4.5}, {"text": "one thing you could do is you know make", "start": 808.35, "duration": 6.599}, {"text": "a photos product around the idea that", "start": 810.66, "duration": 5.549}, {"text": "you can actually understand what's in", "start": 814.949, "duration": 2.491}, {"text": "people's photos and that's been going", "start": 816.209, "duration": 7.261}, {"text": "really well as a lesson for for you who", "start": 817.44, "duration": 8.43}, {"text": "are starting companies often applied", "start": 823.47, "duration": 4.71}, {"text": "domains I think it's really important to", "start": 825.87, "duration": 5.1}, {"text": "be able to look at the machine learning", "start": 828.18, "duration": 4.56}, {"text": "work that is happening in the world and", "start": 830.97, "duration": 4.799}, {"text": "realize that Austin you can reuse many", "start": 832.74, "duration": 5.13}, {"text": "of the same ideas from one domain and", "start": 835.769, "duration": 4.44}, {"text": "just by pointing at it kind of different", "start": 837.87, "duration": 4.589}, {"text": "data sets get completely different", "start": 840.209, "duration": 5.63}, {"text": "interesting product features so if you", "start": 842.459, "duration": 5.88}, {"text": "for example use the same basic model", "start": 845.839, "duration": 3.821}, {"text": "structure training on different data and", "start": 848.339, "duration": 2.281}, {"text": "you get something different", "start": 849.66, "duration": 3.869}, {"text": "one general model trend is given an", "start": 850.62, "duration": 4.889}, {"text": "image predict interesting pixels so", "start": 853.529, "duration": 5.43}, {"text": "there's a bunch of you know ways you", "start": 855.509, "duration": 4.621}, {"text": "could do that but if you have a model", "start": 858.959, "duration": 5.521}, {"text": "structure that does that my summer", "start": 860.13, "duration": 6.03}, {"text": "intern from a few years ago Matt velar", "start": 864.48, "duration": 3.57}, {"text": "who actually went off to found clarify", "start": 866.16, "duration": 5.549}, {"text": "which is a computer vision company we", "start": 868.05, "duration": 5.01}, {"text": "were working in collaboration with the", "start": 871.709, "duration": 4.771}, {"text": "street view team on identifying text in", "start": 873.06, "duration": 6.57}, {"text": "Street View images and so to do that you", "start": 876.48, "duration": 4.799}, {"text": "can have training data where people have", "start": 879.63, "duration": 4.11}, {"text": "circled or drawn boxes around text and", "start": 881.279, "duration": 4.321}, {"text": "you just try to predict the heatmap of", "start": 883.74, "duration": 4.529}, {"text": "which pixels contain text in a Street", "start": 885.6, "duration": 6.179}, {"text": "View image and so this works reasonably", "start": 888.269, "duration": 5.76}, {"text": "well and then you can run an OCR model", "start": 891.779, "duration": 4.381}, {"text": "on those pixels and actually read the", "start": 894.029, "duration": 5.521}, {"text": "text and it works you know across lots", "start": 896.16, "duration": 5.58}, {"text": "of different font sizes and colors and", "start": 899.55, "duration": 4.289}, {"text": "whether it's close too far from the from", "start": 901.74, "duration": 5.88}, {"text": "the camera and so then some people in", "start": 903.839, "duration": 6.031}, {"text": "the Maps team decided they would build", "start": 907.62, "duration": 4.85}, {"text": "this thing that would help you identify", "start": 909.87, "duration": 5.49}, {"text": "whether your rooftop has solar energy", "start": 912.47, "duration": 5.14}, {"text": "potential and how much energy you could", "start": 915.36, "duration": 4.68}, {"text": "generate by installing solar panels and", "start": 917.61, "duration": 4.079}, {"text": "so obviously one of the first things you", "start": 920.04, "duration": 3.0}, {"text": "have to do is find rooftops and", "start": 921.689, "duration": 2.881}, {"text": "that's exactly the same model but just", "start": 923.04, "duration": 3.18}, {"text": "with different training data where you", "start": 924.57, "duration": 3.629}, {"text": "now have circles around rooftops and", "start": 926.22, "duration": 3.69}, {"text": "then there's a bunch of other work to", "start": 928.199, "duration": 3.661}, {"text": "estimate the angle of the rooftop from", "start": 929.91, "duration": 4.619}, {"text": "the imagery or multiple views of the", "start": 931.86, "duration": 5.969}, {"text": "same same house and then some stuff to", "start": 934.529, "duration": 5.25}, {"text": "predict you know what is the solar", "start": 937.829, "duration": 5.31}, {"text": "energy potential for that in another", "start": 939.779, "duration": 5.761}, {"text": "area where we've applied this is in the", "start": 943.139, "duration": 4.26}, {"text": "medical domain so the same basic model", "start": 945.54, "duration": 5.969}, {"text": "we want to be able to say take a medical", "start": 947.399, "duration": 6.211}, {"text": "imaging problem one of the first ones", "start": 951.509, "duration": 5.611}, {"text": "we've been tackling is ophthalmology", "start": 953.61, "duration": 5.52}, {"text": "problems and in particular taking a", "start": 957.12, "duration": 3.57}, {"text": "retinal image like this and tackling", "start": 959.13, "duration": 4.05}, {"text": "deciding whether or not this has", "start": 960.69, "duration": 5.25}, {"text": "symptoms of a degenerative disease", "start": 963.18, "duration": 5.37}, {"text": "called diabetic retinopathy and so this", "start": 965.94, "duration": 4.259}, {"text": "is again the same kind of problem you", "start": 968.55, "duration": 3.57}, {"text": "want identify parts of the eye that are", "start": 970.199, "duration": 5.01}, {"text": "related to you know that seem to be", "start": 972.12, "duration": 6.389}, {"text": "diseased in some way and then you also", "start": 975.209, "duration": 4.74}, {"text": "have a whole image classification", "start": 978.509, "duration": 3.871}, {"text": "problem of does this eye show symptoms", "start": 979.949, "duration": 5.221}, {"text": "at the level of one two three four or", "start": 982.38, "duration": 6.269}, {"text": "five and turns out you can do this so", "start": 985.17, "duration": 6.599}, {"text": "some people in our group have done a", "start": 988.649, "duration": 6.841}, {"text": "really nice sort of medical study", "start": 991.769, "duration": 7.471}, {"text": "showing that if you collect 150,000", "start": 995.49, "duration": 6.12}, {"text": "ophthalmology images and then you get", "start": 999.24, "duration": 3.99}, {"text": "each one labeled by seven", "start": 1001.61, "duration": 3.779}, {"text": "ophthalmologists because if you ask two", "start": 1003.23, "duration": 3.63}, {"text": "ophthalmologists degrade the same image", "start": 1005.389, "duration": 4.081}, {"text": "one two three four or five they agree 60", "start": 1006.86, "duration": 4.83}, {"text": "percent of the time - slightly", "start": 1009.47, "duration": 4.08}, {"text": "terrifying if you ask the same", "start": 1011.69, "duration": 3.72}, {"text": "ophthalmologist to grade the same image", "start": 1013.55, "duration": 3.81}, {"text": "a few hours later they agree with", "start": 1015.41, "duration": 3.33}, {"text": "themselves sixty five percent of the", "start": 1017.36, "duration": 5.729}, {"text": "time and and that's mildly terrifying so", "start": 1018.74, "duration": 5.76}, {"text": "we had to get every image labeled by", "start": 1023.089, "duration": 3.031}, {"text": "seven ophthalmologists to reduce the", "start": 1024.5, "duration": 3.36}, {"text": "variance in the score and say oh it's", "start": 1026.12, "duration": 3.78}, {"text": "five people think it's a two so it's", "start": 1027.86, "duration": 3.469}, {"text": "probably more like a tooth and a three", "start": 1029.9, "duration": 3.84}, {"text": "but in any case the the punchline of", "start": 1031.329, "duration": 4.691}, {"text": "this paper is we now have a model that", "start": 1033.74, "duration": 5.429}, {"text": "performs on par slightly better than the", "start": 1036.02, "duration": 5.85}, {"text": "median of eight US board-certified", "start": 1039.169, "duration": 5.52}, {"text": "optimal which is cool because there's a", "start": 1041.87, "duration": 3.99}, {"text": "bunch of places in the world especially", "start": 1044.689, "duration": 3.841}, {"text": "in India and other countries where there", "start": 1045.86, "duration": 4.949}, {"text": "are you know many people at risk and", "start": 1048.53, "duration": 2.79}, {"text": "there just aren't enough", "start": 1050.809, "duration": 2.971}, {"text": "ophthalmologists so actually doing", "start": 1051.32, "duration": 4.71}, {"text": "clinical trials in India we've licensed", "start": 1053.78, "duration": 2.82}, {"text": "this", "start": 1056.03, "duration": 2.519}, {"text": "our verily subsidiary whose license it", "start": 1056.6, "duration": 4.079}, {"text": "to a camera an ophthalmology camera", "start": 1058.549, "duration": 3.711}, {"text": "manufacturer who's going to be", "start": 1060.679, "duration": 3.271}, {"text": "integrating this into the actual", "start": 1062.26, "duration": 6.82}, {"text": "ophthalmology camera another area where", "start": 1063.95, "duration": 7.729}, {"text": "being able to see is pretty useful is", "start": 1069.08, "duration": 4.229}, {"text": "robotics if you're trying to build", "start": 1071.679, "duration": 3.581}, {"text": "robots just being able to perceive the", "start": 1073.309, "duration": 3.541}, {"text": "world around you clearly makes things a", "start": 1075.26, "duration": 4.77}, {"text": "lot better so we've been doing a bunch", "start": 1076.85, "duration": 5.97}, {"text": "of experiments both with real robots and", "start": 1080.03, "duration": 7.2}, {"text": "also with simulated robotic environments", "start": 1082.82, "duration": 7.02}, {"text": "and also with trying to do imitation", "start": 1087.23, "duration": 5.939}, {"text": "learning from people performing actions", "start": 1089.84, "duration": 4.74}, {"text": "and then trying to get robots to do so", "start": 1093.169, "duration": 7.25}, {"text": "we set up what we call an arm farm oops", "start": 1094.58, "duration": 8.52}, {"text": "I'm not playing oh maybe I'm not on the", "start": 1100.419, "duration": 5.561}, {"text": "internet well anyway it's not that", "start": 1103.1, "duration": 4.709}, {"text": "exciting except we have a bunch of", "start": 1105.98, "duration": 4.47}, {"text": "robots trying to grasp things and they", "start": 1107.809, "duration": 6.211}, {"text": "can essentially learn to grat learn on", "start": 1110.45, "duration": 5.76}, {"text": "their own whether they're grasping", "start": 1114.02, "duration": 3.779}, {"text": "something successfully by just having a", "start": 1116.21, "duration": 2.73}, {"text": "bin of things in front of them and they", "start": 1117.799, "duration": 3.151}, {"text": "just try to pick something up and if", "start": 1118.94, "duration": 3.42}, {"text": "they fail their gripper closes all the", "start": 1120.95, "duration": 5.4}, {"text": "way if they succeed then they don't", "start": 1122.36, "duration": 5.13}, {"text": "close the gripper all the way and they", "start": 1126.35, "duration": 2.52}, {"text": "can actually see from the camera that", "start": 1127.49, "duration": 3.54}, {"text": "they've managed to pick something up and", "start": 1128.87, "duration": 4.83}, {"text": "so they can practice picking things up", "start": 1131.03, "duration": 5.58}, {"text": "and we can pool all the sensor data from", "start": 1133.7, "duration": 5.27}, {"text": "all the robots that are doing this to", "start": 1136.61, "duration": 5.16}, {"text": "retrain a model every night for grasping", "start": 1138.97, "duration": 6.01}, {"text": "so that the next day's grasping attempts", "start": 1141.77, "duration": 5.61}, {"text": "are better and better and by having lots", "start": 1144.98, "duration": 4.559}, {"text": "of robots do this you actually get a lot", "start": 1147.38, "duration": 3.69}, {"text": "of parallel experience much more than", "start": 1149.539, "duration": 3.0}, {"text": "you can get on a single robotic arm and", "start": 1151.07, "duration": 4.14}, {"text": "so we have a data set of that we've", "start": 1152.539, "duration": 4.311}, {"text": "actually released publicly of about", "start": 1155.21, "duration": 5.87}, {"text": "800,000 grasp attempts versus about", "start": 1156.85, "duration": 6.43}, {"text": "30,000 grasp attempts which is kind of a", "start": 1161.08, "duration": 4.65}, {"text": "big public data set in the past and", "start": 1163.28, "duration": 5.34}, {"text": "surprisingly has grasped attempts gives", "start": 1165.73, "duration": 5.29}, {"text": "you a much better grasping mechanism and", "start": 1168.62, "duration": 5.01}, {"text": "model than 30 of them not surprising", "start": 1171.02, "duration": 5.87}, {"text": "we've also been trying to this is me", "start": 1173.63, "duration": 6.06}, {"text": "awkwardly looking at a robot on a screen", "start": 1176.89, "duration": 5.409}, {"text": "that you can't see doing some actions", "start": 1179.69, "duration": 4.71}, {"text": "I'm going to like mimic the robotic", "start": 1182.299, "duration": 4.681}, {"text": "nature of it and then we have a video of", "start": 1184.4, "duration": 5.06}, {"text": "me doing that and then we're", "start": 1186.98, "duration": 6.71}, {"text": "just trying to learn from the videos to", "start": 1189.46, "duration": 7.29}, {"text": "transfer that action to the real robots", "start": 1193.69, "duration": 6.229}, {"text": "and that's working reasonably well", "start": 1196.75, "duration": 5.64}, {"text": "here's another example and we're doing", "start": 1199.919, "duration": 5.411}, {"text": "that first lluvia simulator and then", "start": 1202.39, "duration": 4.919}, {"text": "we're taking that simulator and then", "start": 1205.33, "duration": 3.599}, {"text": "trying to transfer those activities to a", "start": 1207.309, "duration": 1.98}, {"text": "rebel", "start": 1208.929, "duration": 4.74}, {"text": "real robot and that works reasonably", "start": 1209.289, "duration": 8.37}, {"text": "well as well another place that I'm", "start": 1213.669, "duration": 6.931}, {"text": "pretty excited about deep learning is in", "start": 1217.659, "duration": 5.791}, {"text": "lots and lots of scientific domains you", "start": 1220.6, "duration": 7.579}, {"text": "often have the case where you have a", "start": 1223.45, "duration": 4.729}, {"text": "simulator of some really complex", "start": 1228.96, "duration": 4.78}, {"text": "phenomenon and that's often a sort of", "start": 1230.919, "duration": 5.101}, {"text": "HPC style application and very", "start": 1233.74, "duration": 4.74}, {"text": "computationally expensive but it kind of", "start": 1236.02, "duration": 4.139}, {"text": "gives you insight into whatever", "start": 1238.48, "duration": 3.9}, {"text": "scientific processes are going on and", "start": 1240.159, "duration": 4.201}, {"text": "that allows you to kind of iterate in a", "start": 1242.38, "duration": 5.789}, {"text": "computational science methodology but", "start": 1244.36, "duration": 5.37}, {"text": "often those computations are pretty", "start": 1248.169, "duration": 4.351}, {"text": "expensive and so one of the things we've", "start": 1249.73, "duration": 4.62}, {"text": "been working on and this is just one", "start": 1252.52, "duration": 3.3}, {"text": "example we have a lot of different", "start": 1254.35, "duration": 3.299}, {"text": "fields of science where we've seen this", "start": 1255.82, "duration": 4.68}, {"text": "to be true is you can use those", "start": 1257.649, "duration": 5.071}, {"text": "simulators as training data for an OLAP", "start": 1260.5, "duration": 6.779}, {"text": "so quantum chemists have a similar they", "start": 1262.72, "duration": 6.209}, {"text": "have a problem where they take in a", "start": 1267.279, "duration": 3.601}, {"text": "configuration of molecules and they run", "start": 1268.929, "duration": 3.87}, {"text": "a bunch of time steps and then at the", "start": 1270.88, "duration": 3.51}, {"text": "end they get some information about how", "start": 1272.799, "duration": 3.661}, {"text": "the ultimate configuration of those", "start": 1274.39, "duration": 5.1}, {"text": "molecules turns out and from that they", "start": 1276.46, "duration": 4.89}, {"text": "get a few properties about those", "start": 1279.49, "duration": 4.049}, {"text": "molecules like is it toxic did it bind", "start": 1281.35, "duration": 4.709}, {"text": "or something else you know a handful of", "start": 1283.539, "duration": 4.801}, {"text": "these things so it turns out that's the", "start": 1286.059, "duration": 4.951}, {"text": "data that if you use that as input you", "start": 1288.34, "duration": 6.15}, {"text": "run this really expensive simulator for", "start": 1291.01, "duration": 5.19}, {"text": "an hour then you get these thirty", "start": 1294.49, "duration": 5.85}, {"text": "numbers out that turns out to be great", "start": 1296.2, "duration": 5.849}, {"text": "training data for an ER lab and so you", "start": 1300.34, "duration": 3.15}, {"text": "can train a neural net to do exactly", "start": 1302.049, "duration": 3.271}, {"text": "that same tasks or to approximately that", "start": 1303.49, "duration": 4.85}, {"text": "task approximate the entire simulator", "start": 1305.32, "duration": 6.06}, {"text": "and you can essentially the punch line", "start": 1308.34, "duration": 5.319}, {"text": "is the bottom there you essentially get", "start": 1311.38, "duration": 4.049}, {"text": "indistinguishable accuracy from using", "start": 1313.659, "duration": 3.031}, {"text": "the real simulator but it's three", "start": 1315.429, "duration": 3.141}, {"text": "hundred thousand times faster and that", "start": 1316.69, "duration": 4.349}, {"text": "has a lot of implications for how you", "start": 1318.57, "duration": 3.68}, {"text": "might do", "start": 1321.039, "duration": 2.771}, {"text": "quantum chemistry if you suddenly have", "start": 1322.25, "duration": 5.01}, {"text": "something 300,000 times faster you might", "start": 1323.81, "duration": 6.12}, {"text": "like run 100 million things through your", "start": 1327.26, "duration": 6.39}, {"text": "through your simulated neural lipase", "start": 1329.93, "duration": 6.65}, {"text": "emulator and figure out what's going on", "start": 1333.65, "duration": 5.49}, {"text": "look and you know to identify a bunch of", "start": 1336.58, "duration": 4.03}, {"text": "candidates that you might want to look", "start": 1339.14, "duration": 4.62}, {"text": "into in more detail so that's exciting", "start": 1340.61, "duration": 5.91}, {"text": "another place where these kinds of pixel", "start": 1343.76, "duration": 7.86}, {"text": "to pixel models come in is some people", "start": 1346.52, "duration": 7.89}, {"text": "in Google have done a model that tries", "start": 1351.62, "duration": 5.01}, {"text": "to predict depth from an input image and", "start": 1354.41, "duration": 4.59}, {"text": "we have some training data where we have", "start": 1356.63, "duration": 5.7}, {"text": "the true depths given a the camera", "start": 1359.0, "duration": 5.16}, {"text": "viewpoint and where things are in the", "start": 1362.33, "duration": 4.44}, {"text": "room or in the world and then we try to", "start": 1364.16, "duration": 4.35}, {"text": "train a model to do predicted depths", "start": 1366.77, "duration": 3.3}, {"text": "from just the raw pixels of that image", "start": 1368.51, "duration": 4.98}, {"text": "so that's a pixel to pixel learning", "start": 1370.07, "duration": 5.13}, {"text": "problem and you can imagine a lot of", "start": 1373.49, "duration": 4.56}, {"text": "pixel pixel learning problems and indeed", "start": 1375.2, "duration": 5.39}, {"text": "you know one one application and in", "start": 1378.05, "duration": 6.3}, {"text": "cameras is you want to predict depth and", "start": 1380.59, "duration": 5.56}, {"text": "a portrait and then you can do kind of", "start": 1384.35, "duration": 4.41}, {"text": "funky cool effects like identify the", "start": 1386.15, "duration": 4.44}, {"text": "person in the foreground and turn the", "start": 1388.76, "duration": 3.99}, {"text": "background black and white or like make", "start": 1390.59, "duration": 4.64}, {"text": "it all fuzzy and artsy in the background", "start": 1392.75, "duration": 5.25}, {"text": "which is kind of cool but it turns out", "start": 1395.23, "duration": 5.41}, {"text": "you can also take microscope microscope", "start": 1398.0, "duration": 5.79}, {"text": "images as the raw microscope images", "start": 1400.64, "duration": 7.67}, {"text": "input and then the chemically stained", "start": 1403.79, "duration": 7.44}, {"text": "microscope image as the target for your", "start": 1408.31, "duration": 5.95}, {"text": "model and so for example that's often", "start": 1411.23, "duration": 5.7}, {"text": "how people see you know cell bodies and", "start": 1414.26, "duration": 5.31}, {"text": "cell boundaries is you apply different", "start": 1416.93, "duration": 4.86}, {"text": "kinds of stains to the cells and then", "start": 1419.57, "duration": 3.6}, {"text": "you can make them show up on a", "start": 1421.79, "duration": 2.85}, {"text": "microscope better and you can see what's", "start": 1423.17, "duration": 3.74}, {"text": "going on", "start": 1424.64, "duration": 2.27}, {"text": "well it turns out so this animation", "start": 1427.28, "duration": 7.98}, {"text": "that's the input that's the ground truth", "start": 1431.57, "duration": 6.18}, {"text": "and that's the predicted output of a", "start": 1435.26, "duration": 3.99}, {"text": "neural net that's trained to sort of", "start": 1437.75, "duration": 2.79}, {"text": "virtually stain something without", "start": 1439.25, "duration": 5.1}, {"text": "actually staining it and this is", "start": 1440.54, "duration": 7.56}, {"text": "important because it turns out when you", "start": 1444.35, "duration": 5.4}, {"text": "actually stain something that kills the", "start": 1448.1, "duration": 3.39}, {"text": "cells so you don't get any temporal", "start": 1449.75, "duration": 4.2}, {"text": "information about what's going on in the", "start": 1451.49, "duration": 4.56}, {"text": "cells essentially die when you apply the", "start": 1453.95, "duration": 4.71}, {"text": "stain but here you can virtually stain", "start": 1456.05, "duration": 3.99}, {"text": "something but then follow them", "start": 1458.66, "duration": 4.14}, {"text": "longitudinally in time and see how cell", "start": 1460.04, "duration": 5.25}, {"text": "processes kind of continue to happen", "start": 1462.8, "duration": 5.76}, {"text": "without actually staining them you can", "start": 1465.29, "duration": 6.24}, {"text": "also stain for things that you can't", "start": 1468.56, "duration": 5.31}, {"text": "actually really necessarily develop a", "start": 1471.53, "duration": 5.07}, {"text": "true chemical stain so if you have some", "start": 1473.87, "duration": 4.71}, {"text": "one label which things are axons in", "start": 1476.6, "duration": 3.33}, {"text": "which things are dendrites and neural", "start": 1478.58, "duration": 3.69}, {"text": "tissue you can have a microscope viewer", "start": 1479.93, "duration": 4.71}, {"text": "that highlights axons and dendrites and", "start": 1482.27, "duration": 6.03}, {"text": "different colors and cell bodies even if", "start": 1484.64, "duration": 5.25}, {"text": "that's kind of not something that you", "start": 1488.3, "duration": 5.33}, {"text": "can chemically do with a real stained", "start": 1489.89, "duration": 3.74}, {"text": "one of the areas we've been doing a lot", "start": 1494.11, "duration": 5.61}, {"text": "of work is in language understanding", "start": 1496.01, "duration": 8.85}, {"text": "models and so this started out as", "start": 1499.72, "duration": 8.62}, {"text": "research in our group to do essentially", "start": 1504.86, "duration": 6.09}, {"text": "sequence the sequence learning so you", "start": 1508.34, "duration": 4.53}, {"text": "have some input sequence and conditioned", "start": 1510.95, "duration": 3.39}, {"text": "on that input sequence you want to", "start": 1512.87, "duration": 4.2}, {"text": "predict an output sequence so this turns", "start": 1514.34, "duration": 4.23}, {"text": "out to be useful for actually a whole", "start": 1517.07, "duration": 4.23}, {"text": "bunch of different problems but one of", "start": 1518.57, "duration": 5.58}, {"text": "them is translation so if you have a", "start": 1521.3, "duration": 5.31}, {"text": "bunch of sentence pairs one in french", "start": 1524.15, "duration": 4.62}, {"text": "and the corresponding meaning sentence", "start": 1526.61, "duration": 4.44}, {"text": "in english then you can use a sequence", "start": 1528.77, "duration": 4.08}, {"text": "the sequence model to take the input", "start": 1531.05, "duration": 4.77}, {"text": "sentence one word at a time or even like", "start": 1532.85, "duration": 5.52}, {"text": "one character at a time and then when", "start": 1535.82, "duration": 5.04}, {"text": "you hit a special end of french token", "start": 1538.37, "duration": 4.92}, {"text": "then you essentially start spitting out", "start": 1540.86, "duration": 4.83}, {"text": "the corresponding english meaning in", "start": 1543.29, "duration": 4.35}, {"text": "english translation of that scent of", "start": 1545.69, "duration": 4.59}, {"text": "that french sentence and so that worked", "start": 1547.64, "duration": 5.79}, {"text": "like this and you have training data", "start": 1550.28, "duration": 5.58}, {"text": "that is like that and use try to predict", "start": 1553.43, "duration": 4.22}, {"text": "the next word from that train engine", "start": 1555.86, "duration": 4.12}, {"text": "using recurrent neural net", "start": 1557.65, "duration": 4.43}, {"text": "and that turns out to work reasonably", "start": 1559.98, "duration": 5.46}, {"text": "well and then you're actually trying to", "start": 1562.08, "duration": 7.68}, {"text": "find the most probable sequence not the", "start": 1565.44, "duration": 6.39}, {"text": "sequence with the most probable", "start": 1569.76, "duration": 4.35}, {"text": "individual individual terms and so you", "start": 1571.83, "duration": 3.719}, {"text": "do a little beam search where you kind", "start": 1574.11, "duration": 4.29}, {"text": "of keep a window of candidates and you", "start": 1575.549, "duration": 5.401}, {"text": "sort of search over possible vocabulary", "start": 1578.4, "duration": 5.73}, {"text": "items until you are happy and found a", "start": 1580.95, "duration": 6.24}, {"text": "likely output sequence and that's how", "start": 1584.13, "duration": 6.81}, {"text": "you do translation so one application of", "start": 1587.19, "duration": 6.75}, {"text": "this is in Gmail we had we added a", "start": 1590.94, "duration": 4.44}, {"text": "feature called Smart reply where", "start": 1593.94, "duration": 3.66}, {"text": "essentially we get an incoming email so", "start": 1595.38, "duration": 3.96}, {"text": "this is one sent to my colleague Greg", "start": 1597.6, "duration": 4.26}, {"text": "Corrado from his brother hi we want to", "start": 1599.34, "duration": 4.2}, {"text": "invite you to join us for Thanksgiving", "start": 1601.86, "duration": 4.439}, {"text": "dinner please bring your favorite dish", "start": 1603.54, "duration": 5.31}, {"text": "RSVP go next week so to reduce the", "start": 1606.299, "duration": 3.931}, {"text": "computational cost we have a small", "start": 1608.85, "duration": 3.27}, {"text": "feed-forward neural net that says is", "start": 1610.23, "duration": 3.3}, {"text": "this the kind of thing where a small", "start": 1612.12, "duration": 4.049}, {"text": "short reply would make sense and if yes", "start": 1613.53, "duration": 5.49}, {"text": "then we going to activate a sequence the", "start": 1616.169, "duration": 5.461}, {"text": "sequence model and we're going to do a", "start": 1619.02, "duration": 3.75}, {"text": "much more computationally expensive", "start": 1621.63, "duration": 4.169}, {"text": "thing with that in messages input and", "start": 1622.77, "duration": 4.56}, {"text": "then we're going to try to predict", "start": 1625.799, "duration": 5.431}, {"text": "plausible replies and so this system", "start": 1627.33, "duration": 6.839}, {"text": "produces three it says count us in will", "start": 1631.23, "duration": 4.74}, {"text": "be there or sorry we won't be able to", "start": 1634.169, "duration": 4.111}, {"text": "make it and so this is a nice", "start": 1635.97, "duration": 3.81}, {"text": "application of sequence of sequence", "start": 1638.28, "duration": 6.029}, {"text": "models and if you squint in the world", "start": 1639.78, "duration": 6.21}, {"text": "you'll find lots of applications of", "start": 1644.309, "duration": 5.521}, {"text": "these and so turns out to my reply in", "start": 1645.99, "duration": 6.569}, {"text": "April 2009 there was an April Fool's", "start": 1649.83, "duration": 4.44}, {"text": "joke that Google put out saying haha", "start": 1652.559, "duration": 2.821}, {"text": "we're going to reply to your email", "start": 1654.27, "duration": 3.09}, {"text": "automatically huh", "start": 1655.38, "duration": 4.71}, {"text": "but then in November 2 2015 we launched", "start": 1657.36, "duration": 6.21}, {"text": "this as a real product and in just three", "start": 1660.09, "duration": 5.61}, {"text": "months 10 percent of mobile inbox", "start": 1663.57, "duration": 4.739}, {"text": "replies are generated by the smart", "start": 1665.7, "duration": 8.09}, {"text": "replies so that's kind of cool but", "start": 1668.309, "duration": 8.37}, {"text": "obviously one of the real potential", "start": 1673.79, "duration": 4.57}, {"text": "applications of this was Translate which", "start": 1676.679, "duration": 3.87}, {"text": "is what we were doing demonstrating that", "start": 1678.36, "duration": 5.63}, {"text": "this research was effective on on a", "start": 1680.549, "duration": 6.75}, {"text": "large by academic standards but smallish", "start": 1683.99, "duration": 6.61}, {"text": "public data set of translation data", "start": 1687.299, "duration": 6.38}, {"text": "called WMT so when we look to work on", "start": 1690.6, "duration": 4.77}, {"text": "applying this to the real Google", "start": 1693.679, "duration": 4.061}, {"text": "Translate product we actually had a", "start": 1695.37, "duration": 4.38}, {"text": "hundred X to a thousand X as much", "start": 1697.74, "duration": 4.23}, {"text": "training data and so scaling this up was", "start": 1699.75, "duration": 5.549}, {"text": "actually pretty challenging and we", "start": 1701.97, "duration": 5.31}, {"text": "wanted to make the model a lot higher", "start": 1705.299, "duration": 4.321}, {"text": "quality but we did a nice fairly", "start": 1707.28, "duration": 3.99}, {"text": "detailed write-up of the engineering", "start": 1709.62, "duration": 4.38}, {"text": "behind that in this many many out there", "start": 1711.27, "duration": 8.22}, {"text": "paper and so this is kind of the", "start": 1714.0, "duration": 7.35}, {"text": "structure of the model that we came up", "start": 1719.49, "duration": 5.189}, {"text": "with it has a very deep lsdm stack each", "start": 1721.35, "duration": 6.449}, {"text": "of which runs on different GPU there's", "start": 1724.679, "duration": 5.281}, {"text": "an attention module so that rather than", "start": 1727.799, "duration": 3.811}, {"text": "just having a single state that's", "start": 1729.96, "duration": 3.87}, {"text": "updated by the recurrent model you keep", "start": 1731.61, "duration": 3.689}, {"text": "track of all the states and then you", "start": 1733.83, "duration": 2.79}, {"text": "learn to pay attention to different", "start": 1735.299, "duration": 2.851}, {"text": "parts of the input data when you're", "start": 1736.62, "duration": 3.87}, {"text": "generating different parts of the output", "start": 1738.15, "duration": 5.31}, {"text": "sequence so you're about to generate you", "start": 1740.49, "duration": 5.4}, {"text": "know the next word and you look back at", "start": 1743.46, "duration": 4.699}, {"text": "the word hello and the input sentence", "start": 1745.89, "duration": 7.409}, {"text": "and so on and so this thing runs on one", "start": 1748.159, "duration": 6.821}, {"text": "replica of this model runs on a machine", "start": 1753.299, "duration": 3.51}, {"text": "with a GPU cards with different pieces", "start": 1754.98, "duration": 4.77}, {"text": "of it in different places and then we", "start": 1756.809, "duration": 6.811}, {"text": "run a lot of copies of this model to do", "start": 1759.75, "duration": 5.94}, {"text": "data parallelism across the large", "start": 1763.62, "duration": 4.95}, {"text": "training data and we share the", "start": 1765.69, "duration": 5.099}, {"text": "parameters so this is a technique we've", "start": 1768.57, "duration": 3.51}, {"text": "been using for quite a while that we", "start": 1770.789, "duration": 4.921}, {"text": "originally published in 2012 about what", "start": 1772.08, "duration": 5.69}, {"text": "we call at that time a parameter server", "start": 1775.71, "duration": 5.73}, {"text": "and then using many parallel data data", "start": 1777.77, "duration": 5.8}, {"text": "parallel copies to process different", "start": 1781.44, "duration": 5.16}, {"text": "input data all trying to update those", "start": 1783.57, "duration": 5.219}, {"text": "shared parameters by applying gradients", "start": 1786.6, "duration": 4.829}, {"text": "to those parameters and this allows you", "start": 1788.789, "duration": 5.791}, {"text": "to scale training quite quickly so you", "start": 1791.429, "duration": 5.641}, {"text": "can have you know 50 replicas of this", "start": 1794.58, "duration": 5.4}, {"text": "kind of setup for 20 I think in this", "start": 1797.07, "duration": 4.92}, {"text": "case we were using about 16 so we're", "start": 1799.98, "duration": 5.819}, {"text": "using 100 GPU cards to train a model and", "start": 1801.99, "duration": 7.62}, {"text": "the really good news is the blue line", "start": 1805.799, "duration": 7.26}, {"text": "here is the old phrase based machine", "start": 1809.61, "duration": 5.22}, {"text": "translation system they didn't really", "start": 1813.059, "duration": 3.391}, {"text": "have much machine learning it any", "start": 1814.83, "duration": 3.0}, {"text": "machine learning in it had large", "start": 1816.45, "duration": 3.39}, {"text": "statistical models for lots of different", "start": 1817.83, "duration": 4.46}, {"text": "sub pieces of problem so it had a a", "start": 1819.84, "duration": 4.77}, {"text": "target language model that told you how", "start": 1822.29, "duration": 4.21}, {"text": "often every five word sequence in", "start": 1824.61, "duration": 4.05}, {"text": "English occurred it had an alignment", "start": 1826.5, "duration": 4.29}, {"text": "model that says how words in English and", "start": 1828.66, "duration": 4.8}, {"text": "French sentences align had a phrase", "start": 1830.79, "duration": 4.73}, {"text": "table and a dictionary of plausible", "start": 1833.46, "duration": 5.66}, {"text": "english and french phrases and sentences", "start": 1835.52, "duration": 6.73}, {"text": "and it was like five hundred thousand", "start": 1839.12, "duration": 4.36}, {"text": "lines of code to glue this whole thing", "start": 1842.25, "duration": 3.54}, {"text": "together and that's the blue line and", "start": 1843.48, "duration": 4.8}, {"text": "what we're showing is the quality of", "start": 1845.79, "duration": 4.41}, {"text": "translations generated by that system as", "start": 1848.28, "duration": 7.23}, {"text": "judged by humans and the green line has", "start": 1850.2, "duration": 8.75}, {"text": "a substantial jump in quality for", "start": 1855.51, "duration": 6.06}, {"text": "basically nearly every language pair", "start": 1858.95, "duration": 4.36}, {"text": "jumps up very substantially it doesn't", "start": 1861.57, "duration": 3.18}, {"text": "look like much but those are really big", "start": 1863.31, "duration": 5.07}, {"text": "jumps and quality and the other nice", "start": 1864.75, "duration": 6.15}, {"text": "thing is that system is 500 lines of", "start": 1868.38, "duration": 4.32}, {"text": "tensorflow code instead of 500 thousand", "start": 1870.9, "duration": 4.79}, {"text": "lines of GUI code with like lots of", "start": 1872.7, "duration": 7.44}, {"text": "handwritten logic and the greet the", "start": 1875.69, "duration": 8.23}, {"text": "yellow line on top is human bilingual", "start": 1880.14, "duration": 5.61}, {"text": "human not professional translator but", "start": 1883.92, "duration": 3.5}, {"text": "some of the speaks both those languages", "start": 1885.75, "duration": 4.74}, {"text": "translations as judged by other humans", "start": 1887.42, "duration": 5.38}, {"text": "and so you can see that for some", "start": 1890.49, "duration": 3.54}, {"text": "language Spurs were actually getting", "start": 1892.8, "duration": 4.08}, {"text": "quite close to that human level quality", "start": 1894.03, "duration": 5.52}, {"text": "for translation which is pretty exciting", "start": 1896.88, "duration": 6.12}, {"text": "and when we we were trying to kind of", "start": 1899.55, "duration": 5.1}, {"text": "roll this out slowly across lots of", "start": 1903.0, "duration": 3.45}, {"text": "different language pairs and so we", "start": 1904.65, "duration": 3.39}, {"text": "launched it in the dead of night in", "start": 1906.45, "duration": 5.55}, {"text": "Japan and all of a sudden all of Japan", "start": 1908.04, "duration": 6.18}, {"text": "kind of met many people in Japan noticed", "start": 1912.0, "duration": 4.92}, {"text": "that suddenly English to Japanese", "start": 1914.22, "duration": 4.56}, {"text": "translation was actually usable in", "start": 1916.92, "duration": 4.23}, {"text": "quality as opposed to before but when it", "start": 1918.78, "duration": 5.1}, {"text": "was kind of supported but not usable as", "start": 1921.15, "duration": 5.03}, {"text": "one of the people on our translate team", "start": 1923.88, "duration": 5.97}, {"text": "referred to it and so this professor at", "start": 1926.18, "duration": 7.15}, {"text": "a Japanese university decided we did", "start": 1929.85, "duration": 6.09}, {"text": "this experiment translating the first", "start": 1933.33, "duration": 4.35}, {"text": "paragraph of Hemingway's the snows of", "start": 1935.94, "duration": 4.2}, {"text": "Kilimanjaro to Japanese in the back and", "start": 1937.68, "duration": 5.1}, {"text": "see what the quality looked like and so", "start": 1940.14, "duration": 4.2}, {"text": "if we focus on the last sentence the old", "start": 1942.78, "duration": 3.99}, {"text": "phrase day system says whether the", "start": 1944.34, "duration": 3.43}, {"text": "leopard had what the", "start": 1946.77, "duration": 2.53}, {"text": "demand that that altitude there is no", "start": 1947.77, "duration": 4.77}, {"text": "that nobody explained so I think there's", "start": 1949.3, "duration": 4.47}, {"text": "a leopard involved other than that I", "start": 1952.54, "duration": 5.67}, {"text": "really can't understand that and neural", "start": 1953.77, "duration": 6.45}, {"text": "machine translation just generates much", "start": 1958.21, "duration": 3.75}, {"text": "more natural sounding translations so no", "start": 1960.22, "duration": 3.24}, {"text": "one can explain what leopard was seeking", "start": 1961.96, "duration": 3.84}, {"text": "at that altitude and the only mistake it", "start": 1963.46, "duration": 4.83}, {"text": "made was it left out the words up so you", "start": 1965.8, "duration": 4.71}, {"text": "can see how this transforms it from like", "start": 1968.29, "duration": 4.68}, {"text": "really not usable to like actually", "start": 1970.51, "duration": 4.79}, {"text": "pretty good", "start": 1972.97, "duration": 2.33}, {"text": "another area we're doing a lot of", "start": 1975.46, "duration": 4.38}, {"text": "research in is this notion of automating", "start": 1977.05, "duration": 4.49}, {"text": "solution of machine learning problems", "start": 1979.84, "duration": 5.97}, {"text": "what we call learned to learn and the", "start": 1981.54, "duration": 8.35}, {"text": "idea here is that the current way you", "start": 1985.81, "duration": 4.98}, {"text": "solve a machine learning problem", "start": 1989.89, "duration": 3.21}, {"text": "probably many of you your companies are", "start": 1990.79, "duration": 3.81}, {"text": "solving machine learning problems you", "start": 1993.1, "duration": 4.08}, {"text": "have data you have some way of doing", "start": 1994.6, "duration": 4.71}, {"text": "lots of compute a bunch of GPU guard do", "start": 1997.18, "duration": 3.96}, {"text": "something and then you have a human", "start": 1999.31, "duration": 3.66}, {"text": "machine learning expert saying okay I'm", "start": 2001.14, "duration": 4.11}, {"text": "going to try this kind of model use this", "start": 2002.97, "duration": 3.9}, {"text": "learning rate and I'm going to do", "start": 2005.25, "duration": 3.3}, {"text": "transfer learning from this data set and", "start": 2006.87, "duration": 4.49}, {"text": "and then you hopefully get a solution", "start": 2008.55, "duration": 7.53}, {"text": "what we'd like to turn that into is you", "start": 2011.36, "duration": 6.7}, {"text": "have data and maybe use a hundred times", "start": 2016.08, "duration": 3.36}, {"text": "as much compute but you don't need a", "start": 2018.06, "duration": 4.2}, {"text": "human machine learning expert and if we", "start": 2019.44, "duration": 3.72}, {"text": "could do that that would be really", "start": 2022.26, "duration": 2.19}, {"text": "really good because if you think about", "start": 2023.16, "duration": 3.9}, {"text": "what's happening in the world you know", "start": 2024.45, "duration": 3.51}, {"text": "there's probably 10 million", "start": 2027.06, "duration": 2.4}, {"text": "organizations in the world that should", "start": 2027.96, "duration": 2.94}, {"text": "be using machine learning and actually", "start": 2029.46, "duration": 4.89}, {"text": "have probably data in electronic form", "start": 2030.9, "duration": 5.28}, {"text": "that it would be suitable for machine", "start": 2034.35, "duration": 4.08}, {"text": "learning but there's you know order a", "start": 2036.18, "duration": 4.2}, {"text": "thousand organizations that have really", "start": 2038.43, "duration": 3.3}, {"text": "hired machine learning experts in the", "start": 2040.38, "duration": 3.81}, {"text": "world actually tackle some of these", "start": 2041.73, "duration": 6.12}, {"text": "problems so we're trying lots of", "start": 2044.19, "duration": 7.44}, {"text": "different efforts in this area and I'll", "start": 2047.85, "duration": 7.02}, {"text": "talk about two of them one is a way of", "start": 2051.63, "duration": 5.01}, {"text": "designing neural architectures", "start": 2054.87, "duration": 4.23}, {"text": "automatically and the other is a way of", "start": 2056.64, "duration": 6.289}, {"text": "learning optimizers automatically so", "start": 2059.1, "duration": 7.559}, {"text": "architecture search the idea is we want", "start": 2062.929, "duration": 5.74}, {"text": "to have a model generating model so the", "start": 2066.659, "duration": 3.901}, {"text": "same way a human machine learning expert", "start": 2068.669, "duration": 3.181}, {"text": "says I'm going to try this kind of model", "start": 2070.56, "duration": 2.91}, {"text": "we're going to have a model generating", "start": 2071.85, "duration": 3.24}, {"text": "model that's going to spit out models", "start": 2073.47, "duration": 4.77}, {"text": "for this problem to solve to tackle a", "start": 2075.09, "duration": 4.89}, {"text": "particular problem and so the way this", "start": 2078.24, "duration": 3.09}, {"text": "will work is we're going to generate ten", "start": 2079.98, "duration": 1.649}, {"text": "model", "start": 2081.33, "duration": 2.219}, {"text": "architecture's we're going to train each", "start": 2081.629, "duration": 4.591}, {"text": "of them for a few hours and then we're", "start": 2083.549, "duration": 4.5}, {"text": "going to use the loss of the generative", "start": 2086.22, "duration": 3.119}, {"text": "models as a reinforcement learning", "start": 2088.049, "duration": 3.06}, {"text": "signal for the model generating model", "start": 2089.339, "duration": 6.661}, {"text": "and this is sort of just on the realm of", "start": 2091.109, "duration": 8.22}, {"text": "feasible for small problems today but it", "start": 2096.0, "duration": 5.369}, {"text": "actually works for small problems so", "start": 2099.329, "duration": 5.851}, {"text": "here is an example of a model", "start": 2101.369, "duration": 5.7}, {"text": "architecture came up with and you'll see", "start": 2105.18, "duration": 3.929}, {"text": "it looks sort of not like something a", "start": 2107.069, "duration": 4.74}, {"text": "human would have designed the wiring is", "start": 2109.109, "duration": 5.97}, {"text": "kind of crazy and this is see farc n", "start": 2111.809, "duration": 6.21}, {"text": "which is a very small color image", "start": 2115.079, "duration": 4.74}, {"text": "problem with ten different classes got", "start": 2118.019, "duration": 4.941}, {"text": "pictures of horses and planes and cars", "start": 2119.819, "duration": 5.341}, {"text": "not that many classes but it's been", "start": 2122.96, "duration": 3.309}, {"text": "pretty well studied in the machine", "start": 2125.16, "duration": 3.209}, {"text": "learning literature and the error rate", "start": 2126.269, "duration": 4.471}, {"text": "like all machine learning image problems", "start": 2128.369, "duration": 4.351}, {"text": "is been dropping over the years but", "start": 2130.74, "duration": 3.809}, {"text": "everything above these last four lines", "start": 2132.72, "duration": 3.96}, {"text": "is a human generated machine learning", "start": 2134.549, "duration": 6.06}, {"text": "expert model that someone came up with a", "start": 2136.68, "duration": 5.79}, {"text": "new thing and published and beat the", "start": 2140.609, "duration": 4.891}, {"text": "previous state of the art and so this is", "start": 2142.47, "duration": 4.829}, {"text": "the current state of the art and this", "start": 2145.5, "duration": 3.39}, {"text": "neural architecture search basically", "start": 2147.299, "duration": 4.02}, {"text": "with that architecture got very very", "start": 2148.89, "duration": 4.229}, {"text": "close to that state of the art without", "start": 2151.319, "duration": 4.47}, {"text": "any human sort of knowledge of the", "start": 2153.119, "duration": 6.511}, {"text": "underlying architecture we also tried it", "start": 2155.789, "duration": 7.83}, {"text": "on a language modeling task and the", "start": 2159.63, "duration": 5.25}, {"text": "traditional way you do this for", "start": 2163.619, "duration": 4.17}, {"text": "recurrent models is using lsdm cell", "start": 2164.88, "duration": 5.879}, {"text": "whose structure is shown there that's", "start": 2167.789, "duration": 5.52}, {"text": "kind of the default thing you're going", "start": 2170.759, "duration": 3.481}, {"text": "to do if you're going to use any", "start": 2173.309, "duration": 4.081}, {"text": "sequence data and we just gave the", "start": 2174.24, "duration": 5.879}, {"text": "architecture search the sort of", "start": 2177.39, "duration": 5.07}, {"text": "underlying primitives of an LCM cell and", "start": 2180.119, "duration": 5.011}, {"text": "said go to it find us some way of", "start": 2182.46, "duration": 5.22}, {"text": "dealing with sequential data and that's", "start": 2185.13, "duration": 5.219}, {"text": "the salic came up with it looks somewhat", "start": 2187.68, "duration": 5.879}, {"text": "different but in this case it actually", "start": 2190.349, "duration": 4.831}, {"text": "beat the state-of-the-art by a pretty", "start": 2193.559, "duration": 4.651}, {"text": "substantial margin for this language", "start": 2195.18, "duration": 4.649}, {"text": "modeling task and the other interesting", "start": 2198.21, "duration": 4.379}, {"text": "things we then took that cell and used", "start": 2199.829, "duration": 5.46}, {"text": "it on a completely different sequential", "start": 2202.589, "duration": 6.541}, {"text": "task in medical records future", "start": 2205.289, "duration": 6.391}, {"text": "prediction tasks and it performed better", "start": 2209.13, "duration": 4.62}, {"text": "than the metal stem cell in that domain", "start": 2211.68, "duration": 4.399}, {"text": "as well", "start": 2213.75, "duration": 2.329}, {"text": "so learning the optimizer rule is", "start": 2216.699, "duration": 5.01}, {"text": "similar we're going to have symbolic", "start": 2219.64, "duration": 5.159}, {"text": "expressions with and give it the model", "start": 2221.709, "duration": 7.77}, {"text": "the the optimizer of expression learning", "start": 2224.799, "duration": 7.5}, {"text": "model access to the raw primitives that", "start": 2229.479, "duration": 4.59}, {"text": "you might consider using in a neural", "start": 2232.299, "duration": 4.98}, {"text": "optimizer update rule things like here's", "start": 2234.069, "duration": 4.53}, {"text": "the gradient here's the running average", "start": 2237.279, "duration": 3.81}, {"text": "of the recent gradients here's the", "start": 2238.599, "duration": 5.67}, {"text": "momentum term and so the top four lines", "start": 2241.089, "duration": 6.72}, {"text": "here are human designed update rules", "start": 2244.269, "duration": 6.77}, {"text": "that people traditionally use and then", "start": 2247.809, "duration": 5.1}, {"text": "they've been designed over the last", "start": 2251.039, "duration": 7.2}, {"text": "decade or few decades in case of SGD and", "start": 2252.909, "duration": 8.52}, {"text": "are generally what people use Adam as a", "start": 2258.239, "duration": 7.18}, {"text": "pretty good choice these days and often", "start": 2261.429, "duration": 5.88}, {"text": "SGD with momentum which is the second", "start": 2265.419, "duration": 5.31}, {"text": "line is the best choice and what you see", "start": 2267.309, "duration": 6.78}, {"text": "is that this thing came up with 15 or", "start": 2270.729, "duration": 4.38}, {"text": "something completely different", "start": 2274.089, "duration": 3.811}, {"text": "expressions than what we've explored and", "start": 2275.109, "duration": 4.56}, {"text": "they're almost all better than all of", "start": 2277.9, "duration": 5.879}, {"text": "the human design ones and so that's kind", "start": 2279.669, "duration": 6.36}, {"text": "of encouraging that that's going to", "start": 2283.779, "duration": 7.56}, {"text": "appear in ICML and bumpy goop and we", "start": 2286.029, "duration": 7.351}, {"text": "also took one of the most promising ones", "start": 2291.339, "duration": 4.59}, {"text": "of those and we then transferred it to a", "start": 2293.38, "duration": 4.849}, {"text": "different problem where we hadn't the", "start": 2295.929, "duration": 4.65}, {"text": "problem we didn't design the optimizer", "start": 2298.229, "duration": 5.43}, {"text": "on and we use this other optimizer and", "start": 2300.579, "duration": 5.16}, {"text": "found that it gave you no better", "start": 2303.659, "duration": 3.55}, {"text": "training for flex it ease lower is", "start": 2305.739, "duration": 4.56}, {"text": "better for publicity and better loose", "start": 2307.209, "duration": 4.98}, {"text": "core which higher is better for that", "start": 2310.299, "duration": 4.17}, {"text": "metric than Adam which was the best", "start": 2312.189, "duration": 4.83}, {"text": "optimizer we'd found before so I think", "start": 2314.469, "duration": 4.38}, {"text": "this whole motion of learning to learn", "start": 2317.019, "duration": 4.2}, {"text": "is going to be pretty powerful because a", "start": 2318.849, "duration": 4.38}, {"text": "lot of what machine learning experts do", "start": 2321.219, "duration": 4.411}, {"text": "when they sit down to solve a problem is", "start": 2323.229, "duration": 4.95}, {"text": "actually they run lots of experiments", "start": 2325.63, "duration": 6.239}, {"text": "and right now a human can't run that", "start": 2328.179, "duration": 5.43}, {"text": "many experiments right it's just a lot", "start": 2331.869, "duration": 4.44}, {"text": "of cognitive load to run 50 experiments", "start": 2333.609, "duration": 4.68}, {"text": "or 100 experiments and this thing can", "start": 2336.309, "duration": 3.69}, {"text": "run you know twelve thousand experiments", "start": 2338.289, "duration": 3.291}, {"text": "in a weekend", "start": 2339.999, "duration": 3.501}, {"text": "and many of them suck but many of them", "start": 2341.58, "duration": 7.38}, {"text": "don't so the other thing is interesting", "start": 2343.5, "duration": 8.94}, {"text": "is that a lot of what's happened is", "start": 2348.96, "duration": 5.1}, {"text": "we've been able to solve lots of", "start": 2352.44, "duration": 3.57}, {"text": "problems because we have a lot of data", "start": 2354.06, "duration": 3.75}, {"text": "and because we've been able to scale the", "start": 2356.01, "duration": 3.36}, {"text": "amount of compute we throw at different", "start": 2357.81, "duration": 4.89}, {"text": "problems and so really one of the nice", "start": 2359.37, "duration": 5.09}, {"text": "properties of deep learning has is", "start": 2362.7, "duration": 4.59}, {"text": "really transforming how we think about", "start": 2364.46, "duration": 5.59}, {"text": "designing computers these days so deep", "start": 2367.29, "duration": 4.5}, {"text": "learning has two really nice properties", "start": 2370.05, "duration": 4.35}, {"text": "so one is that it's perfectly tolerant", "start": 2371.79, "duration": 4.71}, {"text": "of very reduced precision arithmetic so", "start": 2374.4, "duration": 4.47}, {"text": "you know one significant digit kind of", "start": 2376.5, "duration": 4.98}, {"text": "thing you don't need double precision", "start": 2378.87, "duration": 5.13}, {"text": "you certainly you don't need single", "start": 2381.48, "duration": 4.95}, {"text": "precision floating point and the other", "start": 2384.0, "duration": 5.49}, {"text": "property it has is it's generally made", "start": 2386.43, "duration": 4.47}, {"text": "up all the algorithms I've showed you", "start": 2389.49, "duration": 4.29}, {"text": "are made up of a handful of specific", "start": 2390.9, "duration": 4.44}, {"text": "operations kind of cobbled together in", "start": 2393.78, "duration": 4.35}, {"text": "different ways and so that really leads", "start": 2395.34, "duration": 4.83}, {"text": "to an opportunity where if you can build", "start": 2398.13, "duration": 3.78}, {"text": "custom machine learning Hardware", "start": 2400.17, "duration": 5.24}, {"text": "targeted at doing very reduced precision", "start": 2401.91, "duration": 6.72}, {"text": "linear algebra then you can all of a", "start": 2405.41, "duration": 6.16}, {"text": "sudden unlock huge amounts of compute", "start": 2408.63, "duration": 5.73}, {"text": "relative to CPUs or GPUs or you're not", "start": 2411.57, "duration": 5.64}, {"text": "really targeted at doing these kinds of", "start": 2414.36, "duration": 6.18}, {"text": "things and so this is we've been doing", "start": 2417.21, "duration": 5.4}, {"text": "custom machine learning accelerators for", "start": 2420.54, "duration": 4.71}, {"text": "a while we've had a first generation one", "start": 2422.61, "duration": 3.9}, {"text": "that was targeted at speeding up", "start": 2425.25, "duration": 4.35}, {"text": "inference so not training but inference", "start": 2426.51, "duration": 4.44}, {"text": "when you're actually running a trained", "start": 2429.6, "duration": 5.1}, {"text": "model in in the context of a product we", "start": 2430.95, "duration": 5.52}, {"text": "had our first version", "start": 2434.7, "duration": 4.08}, {"text": "deployed in our data center for two and", "start": 2436.47, "duration": 3.99}, {"text": "a half years or something and we just", "start": 2438.78, "duration": 4.32}, {"text": "revealed this system which is designed", "start": 2440.46, "duration": 5.46}, {"text": "for both training and inference at", "start": 2443.1, "duration": 8.82}, {"text": "Google i/o and this is a board one of", "start": 2445.92, "duration": 8.82}, {"text": "the things we felt was important was to", "start": 2451.92, "duration": 4.71}, {"text": "design not just a chip for training but", "start": 2454.74, "duration": 5.46}, {"text": "also an entire system so because you're", "start": 2456.63, "duration": 5.31}, {"text": "unlikely to get enough compute for large", "start": 2460.2, "duration": 5.16}, {"text": "problems on a single chip so we designed", "start": 2461.94, "duration": 4.98}, {"text": "a really high performance chip and we", "start": 2465.36, "duration": 3.87}, {"text": "also designed them to be hooked together", "start": 2466.92, "duration": 6.26}, {"text": "so this is what we call a pod which is", "start": 2469.23, "duration": 5.849}, {"text": "64 of these Bowl", "start": 2473.18, "duration": 4.629}, {"text": "towards each of which has four chips so", "start": 2475.079, "duration": 5.73}, {"text": "256 chips and that's eleven and a half", "start": 2477.809, "duration": 5.46}, {"text": "petaflop so compute and we're going to", "start": 2480.809, "duration": 4.831}, {"text": "have lots and lots of these in our data", "start": 2483.269, "duration": 4.23}, {"text": "centers which is pretty exciting because", "start": 2485.64, "duration": 3.119}, {"text": "I think we'll be able to tackle much", "start": 2487.499, "duration": 3.06}, {"text": "bigger problems it's going to bring a", "start": 2488.759, "duration": 3.421}, {"text": "lot more compute for someone to learn to", "start": 2490.559, "duration": 5.91}, {"text": "learn approaches and normally", "start": 2492.18, "duration": 5.73}, {"text": "programming a supercomputer is kind of", "start": 2496.469, "duration": 5.28}, {"text": "annoying so we decided we make these", "start": 2497.91, "duration": 5.52}, {"text": "programmable via tensorflow so you", "start": 2501.749, "duration": 4.26}, {"text": "essentially can express a model with a", "start": 2503.43, "duration": 4.139}, {"text": "new interface that we're adding the", "start": 2506.009, "duration": 3.74}, {"text": "tensorflow 1.2 called estimators and", "start": 2507.569, "duration": 5.19}, {"text": "then the same program will run with", "start": 2509.749, "duration": 5.62}, {"text": "minor modifications on CPUs GPUs or on", "start": 2512.759, "duration": 4.77}, {"text": "GPUs and that's going to be available", "start": 2515.369, "duration": 4.281}, {"text": "through Google Cloud you can get a thing", "start": 2517.529, "duration": 5.22}, {"text": "called a cloud TPU later this year which", "start": 2519.65, "duration": 5.169}, {"text": "is going to be a virtual machine we have", "start": 2522.749, "duration": 5.97}, {"text": "180 teraflop TPU version 2 device", "start": 2524.819, "duration": 5.73}, {"text": "attached and it will run tensorflow", "start": 2528.719, "duration": 6.8}, {"text": "program super fast we hope we're also", "start": 2530.549, "duration": 7.2}, {"text": "making a thousand of these devices", "start": 2535.519, "duration": 5.05}, {"text": "available for free to researchers around", "start": 2537.749, "duration": 5.431}, {"text": "the world who are doing interesting work", "start": 2540.569, "duration": 5.46}, {"text": "and want more compute and are committed", "start": 2543.18, "duration": 4.5}, {"text": "to actually publishing the results of", "start": 2546.029, "duration": 3.93}, {"text": "that work openly and also hopefully", "start": 2547.68, "duration": 4.529}, {"text": "giving us feedback about what's working", "start": 2549.959, "duration": 4.41}, {"text": "well on these TPU devices and what's not", "start": 2552.209, "duration": 4.951}, {"text": "and ideally open sourcing code", "start": 2554.369, "duration": 4.89}, {"text": "associated with those models but not", "start": 2557.16, "duration": 3.659}, {"text": "we're not sure that's going to be a hard", "start": 2559.259, "duration": 5.46}, {"text": "requirement but as desire on our part to", "start": 2560.819, "duration": 6.93}, {"text": "help sort of speak up the whole science", "start": 2564.719, "duration": 5.87}, {"text": "and machine learning research ecosystem", "start": 2567.749, "duration": 5.131}, {"text": "and so you can sign up there if you're", "start": 2570.589, "duration": 6.551}, {"text": "interested in any of these things cloud", "start": 2572.88, "duration": 7.619}, {"text": "Google cloud is also producing higher", "start": 2577.14, "duration": 5.49}, {"text": "level api's that are more managed", "start": 2580.499, "duration": 4.23}, {"text": "services or pre trained models that you", "start": 2582.63, "duration": 5.369}, {"text": "can just use without necessarily being a", "start": 2584.729, "duration": 5.13}, {"text": "machine learning expert so if you have", "start": 2587.999, "duration": 4.02}, {"text": "like photographs you can run them", "start": 2589.859, "duration": 3.63}, {"text": "through the vision API and it will read", "start": 2592.019, "duration": 2.911}, {"text": "all the text in it and find all the", "start": 2593.489, "duration": 3.54}, {"text": "faces and tell you what kind of objects", "start": 2594.93, "duration": 4.019}, {"text": "are in it and do all kinds of good stuff", "start": 2597.029, "duration": 4.53}, {"text": "and the translation API has really nice", "start": 2598.949, "duration": 4.29}, {"text": "high-quality translations that might be", "start": 2601.559, "duration": 2.131}, {"text": "useful", "start": 2603.239, "duration": 3.441}, {"text": "lots of things", "start": 2603.69, "duration": 2.99}, {"text": "one final closing thing we've also been", "start": 2607.25, "duration": 4.43}, {"text": "experimenting with machine learning for", "start": 2610.369, "duration": 3.48}, {"text": "doing higher performance machine", "start": 2611.68, "duration": 5.11}, {"text": "learning models and so in this case what", "start": 2613.849, "duration": 5.431}, {"text": "we've been doing is a similar kind of", "start": 2616.79, "duration": 5.13}, {"text": "reinforcement learning where we're going", "start": 2619.28, "duration": 5.039}, {"text": "to take a abstract integrand we have a", "start": 2621.92, "duration": 3.99}, {"text": "bunch of computational devices that we", "start": 2624.319, "duration": 3.811}, {"text": "want to run that on say for GPU cards", "start": 2625.91, "duration": 4.89}, {"text": "and we say to the RL algorithm we want", "start": 2628.13, "duration": 5.28}, {"text": "you to find the placement of tensorflow", "start": 2630.8, "duration": 4.68}, {"text": "operations on two devices that makes", "start": 2633.41, "duration": 4.76}, {"text": "that model run as fast as possible and", "start": 2635.48, "duration": 5.58}, {"text": "nor the current way people do this is", "start": 2638.17, "duration": 5.14}, {"text": "they hit ok for GPU cards I'm going to", "start": 2641.06, "duration": 4.559}, {"text": "run this part of my graph on GPU card 1", "start": 2643.31, "duration": 5.91}, {"text": "this part on GPU card 2 and that's ok", "start": 2645.619, "duration": 4.801}, {"text": "but it's kind of annoying because it's", "start": 2649.22, "duration": 2.609}, {"text": "not something that humans really want to", "start": 2650.42, "duration": 3.449}, {"text": "think about and so we're actually able", "start": 2651.829, "duration": 4.141}, {"text": "to come up with pretty exotic placements", "start": 2653.869, "duration": 3.781}, {"text": "so each color there is a different GPU", "start": 2655.97, "duration": 6.619}, {"text": "card and this is a on the left you see a", "start": 2657.65, "duration": 4.939}, {"text": "sequence prediction model unrolled in", "start": 2662.859, "duration": 4.5}, {"text": "time so different time steps are on", "start": 2665.15, "duration": 5.04}, {"text": "different GPU cards which is not kind of", "start": 2667.359, "duration": 5.561}, {"text": "counterintuitive to what a human expert", "start": 2670.19, "duration": 5.22}, {"text": "would do and this is a image model and", "start": 2672.92, "duration": 4.11}, {"text": "but the punchline is they're basically", "start": 2675.41, "duration": 4.429}, {"text": "20% faster than the human expert", "start": 2677.03, "duration": 8.85}, {"text": "placement that people came up with ok so", "start": 2679.839, "duration": 8.471}, {"text": "now we're here and we think there's a", "start": 2685.88, "duration": 4.05}, {"text": "big opportunity with more compute to", "start": 2688.31, "duration": 5.73}, {"text": "actually accelerate a lot of the use of", "start": 2689.93, "duration": 5.79}, {"text": "machine learning and the sort of", "start": 2694.04, "duration": 3.84}, {"text": "different applications and societal", "start": 2695.72, "duration": 4.139}, {"text": "benefits that you can actually get from", "start": 2697.88, "duration": 4.85}, {"text": "it so I'm pretty excited about that and", "start": 2699.859, "duration": 5.331}, {"text": "you know example queries of the future", "start": 2702.73, "duration": 5.5}, {"text": "you know actually the upper-left one we", "start": 2705.19, "duration": 5.5}, {"text": "can already answer describe this video", "start": 2708.23, "duration": 4.139}, {"text": "in Spanish I didn't show you but we can", "start": 2710.69, "duration": 3.57}, {"text": "actually caption and generate sentences", "start": 2712.369, "duration": 4.5}, {"text": "about images it's probably not that long", "start": 2714.26, "duration": 5.67}, {"text": "before we'll be able to describe a human", "start": 2716.869, "duration": 6.181}, {"text": "video findme documents related to", "start": 2719.93, "duration": 4.649}, {"text": "reinforcement learning for robotics and", "start": 2723.05, "duration": 3.99}, {"text": "summarizes them in German you know", "start": 2724.579, "duration": 4.171}, {"text": "that's pretty complicated request but", "start": 2727.04, "duration": 3.539}, {"text": "imagine how pert that's the kind of", "start": 2728.75, "duration": 2.94}, {"text": "thing you would give to an undergraduate", "start": 2730.579, "duration": 3.811}, {"text": "as like a semester project and then", "start": 2731.69, "duration": 4.11}, {"text": "please come back with a report for me", "start": 2734.39, "duration": 4.36}, {"text": "but imagine if we could actually do that", "start": 2735.8, "duration": 4.96}, {"text": "how much more productive everyone would", "start": 2738.75, "duration": 3.48}, {"text": "be be pretty amazing", "start": 2740.76, "duration": 3.42}, {"text": "and then robotics I think is at a", "start": 2742.23, "duration": 5.58}, {"text": "inflection point where through machine", "start": 2744.18, "duration": 5.31}, {"text": "learning for control we're going to have", "start": 2747.81, "duration": 3.42}, {"text": "robots that can actually operate in", "start": 2749.49, "duration": 3.24}, {"text": "messy environments like this one or the", "start": 2751.23, "duration": 3.78}, {"text": "kitchen over there and actually know how", "start": 2752.73, "duration": 4.74}, {"text": "to manipulate things in a safe way", "start": 2755.01, "duration": 4.08}, {"text": "interacting with humans so that's going", "start": 2757.47, "duration": 5.16}, {"text": "to be exciting too so you already know", "start": 2759.09, "duration": 5.4}, {"text": "this but deep nets are making big", "start": 2762.63, "duration": 5.94}, {"text": "changes and you should pay attention you", "start": 2764.49, "duration": 6.81}, {"text": "can find more info about our work at gzo", "start": 2768.57, "duration": 6.24}, {"text": "slash brain and oh I am you could join", "start": 2771.3, "duration": 4.71}, {"text": "our team but you're already starting", "start": 2774.81, "duration": 9.06}, {"text": "company before we get to questions I", "start": 2776.01, "duration": 10.56}, {"text": "have a poll that requested me to do and", "start": 2783.87, "duration": 4.2}, {"text": "I'm curious too", "start": 2786.57, "duration": 3.6}, {"text": "how many of you are using deep learning", "start": 2788.07, "duration": 7.17}, {"text": "models in what you're doing okay ah how", "start": 2790.17, "duration": 8.64}, {"text": "many of you are using cafe how many of", "start": 2795.24, "duration": 7.2}, {"text": "you are using high torque and a", "start": 2798.81, "duration": 6.93}, {"text": "half-hearted PI torch how many how many", "start": 2802.44, "duration": 10.59}, {"text": "are using piano carols okay and tensors", "start": 2805.74, "duration": 7.88}, {"text": "Wow", "start": 2813.03, "duration": 5.12}, {"text": "okay cool that's good to know", "start": 2813.62, "duration": 7.66}, {"text": "we're excellent yes yes roughly in", "start": 2818.15, "duration": 6.21}, {"text": "proportion in fact ah cool ah", "start": 2821.28, "duration": 9.86}, {"text": "anything to add Zach okay any questions", "start": 2824.36, "duration": 15.46}, {"text": "yeah well I when you talk about sort of", "start": 2831.14, "duration": 10.78}, {"text": "the learning to learn stuff into the", "start": 2839.82, "duration": 4.14}, {"text": "neural net models designing other neural", "start": 2841.92, "duration": 5.55}, {"text": "net models like for example when the", "start": 2843.96, "duration": 4.77}, {"text": "neural net model designed a model that", "start": 2847.47, "duration": 3.42}, {"text": "perform better on C 410 and other models", "start": 2848.73, "duration": 3.9}, {"text": "do you look at those models and say oh I", "start": 2850.89, "duration": 3.36}, {"text": "understand why that performs better or", "start": 2852.63, "duration": 4.47}, {"text": "is it kind of the case that it did", "start": 2854.25, "duration": 4.41}, {"text": "something wacky and you don't understand", "start": 2857.1, "duration": 4.95}, {"text": "really why it works better I mean I", "start": 2858.66, "duration": 6.57}, {"text": "think it depends like some sometimes you", "start": 2862.05, "duration": 5.25}, {"text": "just want the most accurate end model", "start": 2865.23, "duration": 3.6}, {"text": "for the problem you care about and", "start": 2867.3, "duration": 5.02}, {"text": "that's fine sometimes you're trying", "start": 2868.83, "duration": 8.59}, {"text": "to come up with a model and you want to", "start": 2872.32, "duration": 7.02}, {"text": "understand why it's more accurate so", "start": 2877.42, "duration": 4.2}, {"text": "that you can then drive further human", "start": 2879.34, "duration": 4.68}, {"text": "oriented machine learning research so I", "start": 2881.62, "duration": 4.86}, {"text": "think it depends like the symbolic", "start": 2884.02, "duration": 4.11}, {"text": "expressions for the optimizer update", "start": 2886.48, "duration": 3.33}, {"text": "rule those are actually pretty", "start": 2888.13, "duration": 3.87}, {"text": "interpretive all so like if I go back to", "start": 2889.81, "duration": 5.16}, {"text": "the it's acts pretty interesting right", "start": 2892.0, "duration": 8.37}, {"text": "if you look here there's this sub", "start": 2894.97, "duration": 8.04}, {"text": "expression e to the sign of the gradient", "start": 2900.37, "duration": 5.46}, {"text": "times the sign of the momentum that", "start": 2903.01, "duration": 4.95}, {"text": "seems to reoccur in a lot of these", "start": 2905.83, "duration": 4.2}, {"text": "different optimizers that it's learned", "start": 2907.96, "duration": 4.29}, {"text": "and that sort of makes sense basically", "start": 2910.03, "duration": 4.53}, {"text": "if the sign is the same as the direction", "start": 2912.25, "duration": 5.64}, {"text": "you've been going then speed up and if", "start": 2914.56, "duration": 6.51}, {"text": "it's different then slow way down right", "start": 2917.89, "duration": 6.45}, {"text": "and that's kind of a good intuition to", "start": 2921.07, "duration": 4.53}, {"text": "have and you can see that the", "start": 2924.34, "duration": 3.42}, {"text": "reinforcement learning wanted to do that", "start": 2925.6, "duration": 4.65}, {"text": "in like five of these things", "start": 2927.76, "duration": 5.25}, {"text": "so in some sense depending on what", "start": 2930.25, "duration": 4.2}, {"text": "problem you set up and we'll learn to", "start": 2933.01, "duration": 2.82}, {"text": "learn framework you can actually come up", "start": 2934.45, "duration": 4.23}, {"text": "with human insights about oh well that", "start": 2935.83, "duration": 5.52}, {"text": "makes sense from the experiments of", "start": 2938.68, "duration": 8.67}, {"text": "Threatened but you know here that that", "start": 2941.35, "duration": 8.1}, {"text": "you can kind of investigate that cell", "start": 2947.35, "duration": 4.92}, {"text": "and understand if you actually look it's", "start": 2949.45, "duration": 4.89}, {"text": "doing a bunch of ads at the bottom but", "start": 2952.27, "duration": 4.13}, {"text": "it's also doing an element-wise multiply", "start": 2954.34, "duration": 5.28}, {"text": "for the input data in for one of the", "start": 2956.4, "duration": 4.69}, {"text": "paths through the cell which is kind of", "start": 2959.62, "duration": 3.21}, {"text": "different from the lsdm cells doing and", "start": 2961.09, "duration": 3.54}, {"text": "so that might be sort of insight into", "start": 2962.83, "duration": 5.64}, {"text": "why is doing that if you look here you", "start": 2964.63, "duration": 5.4}, {"text": "know I think that architecture is kind", "start": 2968.47, "duration": 4.41}, {"text": "of crazy but we do know from res network", "start": 2970.03, "duration": 5.1}, {"text": "that these skipped connections make a", "start": 2972.88, "duration": 4.44}, {"text": "lot of sense and so this is just kind of", "start": 2975.13, "duration": 4.62}, {"text": "like crazy skip connections and lots of", "start": 2977.32, "duration": 4.11}, {"text": "places oh yeah then I guess maybe a", "start": 2979.75, "duration": 3.03}, {"text": "solid question is do you think this is", "start": 2981.43, "duration": 2.91}, {"text": "going to be a tool for humans to build", "start": 2982.78, "duration": 3.09}, {"text": "better nets or this is going to be how", "start": 2984.34, "duration": 3.18}, {"text": "Nets are built in the futures with other", "start": 2985.87, "duration": 7.5}, {"text": "ah could be both but I will say that", "start": 2987.52, "duration": 8.58}, {"text": "this system can run twelve thousand", "start": 2993.37, "duration": 5.16}, {"text": "experiments in a weekend and humans are", "start": 2996.1, "duration": 5.02}, {"text": "not that good at that", "start": 2998.53, "duration": 5.8}, {"text": "so with all that compute you are showing", "start": 3001.12, "duration": 4.95}, {"text": "it strikes me that you might run out of", "start": 3004.33, "duration": 4.86}, {"text": "human trainable data is that stuff", "start": 3006.07, "duration": 5.49}, {"text": "really for the reinforcement learning", "start": 3009.19, "duration": 5.22}, {"text": "where you can run 12,000 experiments in", "start": 3011.56, "duration": 6.24}, {"text": "a weekend or do you have enough human", "start": 3014.41, "duration": 6.57}, {"text": "labeled data - oh so for example I that", "start": 3017.8, "duration": 6.42}, {"text": "amount on computation when we were", "start": 3020.98, "duration": 5.4}, {"text": "training our translation models for one", "start": 3024.22, "duration": 4.77}, {"text": "language pair we were using hundreds of", "start": 3026.38, "duration": 6.66}, {"text": "GPUs for a week and for that problem", "start": 3028.99, "duration": 6.45}, {"text": "we actually have enough training data", "start": 3033.04, "duration": 3.9}, {"text": "that we could only get through 1/6 of", "start": 3035.44, "duration": 5.49}, {"text": "that data once so we know that if we", "start": 3036.94, "duration": 5.28}, {"text": "could get through all of it the quality", "start": 3040.93, "duration": 2.76}, {"text": "would be way better right because that's", "start": 3042.22, "duration": 3.06}, {"text": "just a general rule of machine learning", "start": 3043.69, "duration": 2.7}, {"text": "if you could get through all your data", "start": 3045.28, "duration": 4.32}, {"text": "probably it'd be better than not and if", "start": 3046.39, "duration": 4.35}, {"text": "you could even go through it a few times", "start": 3049.6, "duration": 3.93}, {"text": "I would value even better so we think", "start": 3050.74, "duration": 4.2}, {"text": "there are plenty of problems where", "start": 3053.53, "duration": 2.67}, {"text": "there's enough labeled data in the world", "start": 3054.94, "duration": 3.06}, {"text": "that you want to tackle a single problem", "start": 3056.2, "duration": 4.08}, {"text": "and a train a single model on something", "start": 3058.0, "duration": 3.87}, {"text": "like that but it's also going to be", "start": 3060.28, "duration": 3.57}, {"text": "pretty good for a small model", "start": 3061.87, "duration": 3.78}, {"text": "exploration where you try to you know", "start": 3063.85, "duration": 3.69}, {"text": "ten thousand different things maybe take", "start": 3065.65, "duration": 3.9}, {"text": "an hour to run on some subset of the", "start": 3067.54, "duration": 3.24}, {"text": "chips it just depends with the problem", "start": 3069.55, "duration": 5.67}, {"text": "you know the architecture search is kind", "start": 3070.78, "duration": 8.28}, {"text": "of tenable with not current generation", "start": 3075.22, "duration": 6.81}, {"text": "but one generation to go GPUs for things", "start": 3079.06, "duration": 4.89}, {"text": "like C far 10 because you run that for", "start": 3082.03, "duration": 3.87}, {"text": "an hour and you get an answer for one of", "start": 3083.95, "duration": 3.0}, {"text": "the experiments and you run twelve", "start": 3085.9, "duration": 3.12}, {"text": "thousand of those so 700 GPUs over a", "start": 3086.95, "duration": 3.84}, {"text": "weekend we know there's a bunch of", "start": 3089.02, "duration": 3.27}, {"text": "algorithmic improvements we could do to", "start": 3090.79, "duration": 3.48}, {"text": "drop that by factor 10 but it's kind of", "start": 3092.29, "duration": 4.08}, {"text": "just on the boundary of practical for", "start": 3094.27, "duration": 5.31}, {"text": "tiny problems and making it practical", "start": 3096.37, "duration": 6.0}, {"text": "for real problems at scale I think", "start": 3099.58, "duration": 5.36}, {"text": "you're going to be really really cool", "start": 3102.37, "duration": 4.68}, {"text": "maybe it may be a follow-up question of", "start": 3104.94, "duration": 3.94}, {"text": "that so you had that slide on there we", "start": 3107.05, "duration": 6.02}, {"text": "have person data compute persons gone", "start": 3108.88, "duration": 7.65}, {"text": "with data do you see anything in the", "start": 3113.07, "duration": 6.52}, {"text": "near term in which you could have really", "start": 3116.53, "duration": 5.31}, {"text": "powerful models on very very small much", "start": 3119.59, "duration": 4.41}, {"text": "smaller data sets than a company like", "start": 3121.84, "duration": 5.1}, {"text": "Google what it would have access to yeah", "start": 3124.0, "duration": 5.34}, {"text": "I mean I think the right way to tackle", "start": 3126.94, "duration": 6.72}, {"text": "that is right now the way we as a", "start": 3129.34, "duration": 5.449}, {"text": "community tackle", "start": 3133.66, "duration": 2.569}, {"text": "learning problems as we say okay we're", "start": 3134.789, "duration": 4.5}, {"text": "going to train a model to do this and we", "start": 3136.229, "duration": 5.161}, {"text": "might say gee we don't have much data", "start": 3139.289, "duration": 3.21}, {"text": "for this problem", "start": 3141.39, "duration": 3.149}, {"text": "we're going to do transfer learning from", "start": 3142.499, "duration": 4.23}, {"text": "imagenet and then I have my 5000 flower", "start": 3144.539, "duration": 3.72}, {"text": "images and I'm going to do transfer", "start": 3146.729, "duration": 3.75}, {"text": "learning and fine tuning on that but", "start": 3148.259, "duration": 4.651}, {"text": "that's really kind of lame right like we", "start": 3150.479, "duration": 4.56}, {"text": "want to build real systems real", "start": 3152.91, "duration": 4.529}, {"text": "intelligent systems we want a model that", "start": 3155.039, "duration": 4.17}, {"text": "knows how to do a thousand things ten", "start": 3157.439, "duration": 3.63}, {"text": "thousand things and then when the ten", "start": 3159.209, "duration": 4.29}, {"text": "thousand first thing comes along we want", "start": 3161.069, "duration": 4.47}, {"text": "it to build on its knowledge for how to", "start": 3163.499, "duration": 3.48}, {"text": "solve those ten thousand things so that", "start": 3165.539, "duration": 2.46}, {"text": "it can solve the ten thousand the first", "start": 3166.979, "duration": 3.27}, {"text": "thing with much less data with many", "start": 3167.999, "duration": 4.32}, {"text": "fewer examples with building on the", "start": 3170.249, "duration": 3.36}, {"text": "representations that's already learned", "start": 3172.319, "duration": 4.17}, {"text": "so if we can build a single giant model", "start": 3173.609, "duration": 5.97}, {"text": "that can do thousands of things that's", "start": 3176.489, "duration": 4.62}, {"text": "going to improve the data efficiency", "start": 3179.579, "duration": 4.38}, {"text": "problem a lot and also the time to the", "start": 3181.109, "duration": 4.801}, {"text": "wall time to actually be able to master", "start": 3183.959, "duration": 4.74}, {"text": "a new task problem as well so I think", "start": 3185.91, "duration": 5.549}, {"text": "that's the way we're going to get to you", "start": 3188.699, "duration": 6.09}, {"text": "know more data efficient more flexible", "start": 3191.459, "duration": 5.25}, {"text": "things because the problem with the", "start": 3194.789, "duration": 3.96}, {"text": "current approach is we train a model do", "start": 3196.709, "duration": 3.9}, {"text": "one thing and then it can't do anything", "start": 3198.749, "duration": 8.19}, {"text": "else which is pretty mean what do your", "start": 3200.609, "duration": 8.34}, {"text": "best engineers do while they're waiting", "start": 3206.939, "duration": 4.991}, {"text": "for model to learn", "start": 3208.949, "duration": 5.211}, {"text": "well they often start up other", "start": 3211.93, "duration": 5.58}, {"text": "experiments and hit reload on the", "start": 3214.16, "duration": 7.14}, {"text": "visualizer they write code they think of", "start": 3217.51, "duration": 7.27}, {"text": "ideas at a whiteboard they do lots of", "start": 3221.3, "duration": 6.12}, {"text": "things but you know getting that that's", "start": 3224.78, "duration": 5.64}, {"text": "like alliteration time down from you", "start": 3227.42, "duration": 7.14}, {"text": "know days or weeks to hours really just", "start": 3230.42, "duration": 6.39}, {"text": "qualitatively changes your workflow and", "start": 3234.56, "duration": 5.19}, {"text": "so I think we're really shooting for", "start": 3236.81, "duration": 6.24}, {"text": "making that time to result as well as", "start": 3239.75, "duration": 6.24}, {"text": "possible and then they won't have you", "start": 3243.05, "duration": 4.65}, {"text": "know people will not have these these", "start": 3245.99, "duration": 4.349}, {"text": "week-long things whether you know gosh I", "start": 3247.7, "duration": 6.18}, {"text": "hope my experiment works so what would", "start": 3250.339, "duration": 5.461}, {"text": "you attribute the gap in translation", "start": 3253.88, "duration": 4.29}, {"text": "quality to between languages is it just", "start": 3255.8, "duration": 5.519}, {"text": "amount of data behind each one I think", "start": 3258.17, "duration": 6.57}, {"text": "some language pairs the the translations", "start": 3261.319, "duration": 5.101}, {"text": "are more natural because they're more", "start": 3264.74, "duration": 3.78}, {"text": "related kinds of language families and", "start": 3266.42, "duration": 4.38}, {"text": "the alignment is maybe the similar as", "start": 3268.52, "duration": 3.63}, {"text": "opposed to a very different word order", "start": 3270.8, "duration": 2.97}, {"text": "and very different character sets for", "start": 3272.15, "duration": 4.439}, {"text": "example but I think ultimately we will", "start": 3273.77, "duration": 5.79}, {"text": "get higher accuracy models by you know", "start": 3276.589, "duration": 5.971}, {"text": "using a pod to train a really big model", "start": 3279.56, "duration": 4.71}, {"text": "and get through all the data once I", "start": 3282.56, "duration": 4.5}, {"text": "suspect we could probably exceed human", "start": 3284.27, "duration": 5.7}, {"text": "quality translations for some language", "start": 3287.06, "duration": 5.82}, {"text": "pairs you know if we get through all the", "start": 3289.97, "duration": 4.29}, {"text": "data once maybe that may be a slightly", "start": 3292.88, "duration": 4.469}, {"text": "bigger model and the analogy is you know", "start": 3294.26, "duration": 5.19}, {"text": "even a the best human translator is only", "start": 3297.349, "duration": 4.171}, {"text": "going to see so many words in their life", "start": 3299.45, "duration": 5.94}, {"text": "and if your translation system can train", "start": 3301.52, "duration": 6.42}, {"text": "a lot more data and see more of them", "start": 3305.39, "duration": 3.63}, {"text": "even though it's probably not as", "start": 3307.94, "duration": 2.73}, {"text": "intelligent and flexible at getting", "start": 3309.02, "duration": 3.69}, {"text": "maximal information for each word that", "start": 3310.67, "duration": 4.62}, {"text": "it sees it maybe at some point gonna do", "start": 3312.71, "duration": 4.73}, {"text": "better", "start": 3315.29, "duration": 2.15}, {"text": "[Music]", "start": 3320.24, "duration": 3.18}, {"text": "so to be honest we haven't experimented", "start": 3328.4, "duration": 4.54}, {"text": "with a broad enough set of tasks to", "start": 3331.29, "duration": 5.82}, {"text": "really make conclusions here I suspect", "start": 3332.94, "duration": 8.73}, {"text": "that there may be tasks I think probably", "start": 3337.11, "duration": 7.8}, {"text": "for any supervised tasks that like where", "start": 3341.67, "duration": 4.89}, {"text": "you have a crisply defined input and", "start": 3344.91, "duration": 3.0}, {"text": "output and you have enough training data", "start": 3346.56, "duration": 4.56}, {"text": "you know it'll probably work it's a", "start": 3347.91, "duration": 4.77}, {"text": "question of how much compute you need to", "start": 3351.12, "duration": 5.43}, {"text": "apply we have a lot of ideas around you", "start": 3352.68, "duration": 5.67}, {"text": "know making the algorithmic search more", "start": 3356.55, "duration": 3.96}, {"text": "efficient by cutting off experiments", "start": 3358.35, "duration": 4.23}, {"text": "that are obviously dead early rather", "start": 3360.51, "duration": 5.04}, {"text": "than running from to conclusion doing", "start": 3362.58, "duration": 3.78}, {"text": "lots of things like that", "start": 3365.55, "duration": 3.3}, {"text": "I think the architecture search itself", "start": 3366.36, "duration": 4.59}, {"text": "right now we train a bespoke model", "start": 3368.85, "duration": 3.81}, {"text": "generating model for each problem we're", "start": 3370.95, "duration": 4.26}, {"text": "trying to solve and so obviously you'd", "start": 3372.66, "duration": 4.14}, {"text": "want to train a model generating models", "start": 3375.21, "duration": 3.48}, {"text": "that solves many problems and then", "start": 3376.8, "duration": 3.75}, {"text": "you'll be able to get in a better state", "start": 3378.69, "duration": 3.95}, {"text": "of good architectures for a new problem", "start": 3380.55, "duration": 4.95}, {"text": "because of seeing similar problems and", "start": 3382.64, "duration": 4.99}, {"text": "you're like oh yeah lots of convolutions", "start": 3385.5, "duration": 4.5}, {"text": "and 12 layers is a good place to start", "start": 3387.63, "duration": 9.39}, {"text": "or something how does the internal", "start": 3390.0, "duration": 9.08}, {"text": "development cycle look like for", "start": 3397.02, "duration": 4.11}, {"text": "optimizing the", "start": 3399.08, "duration": 4.36}, {"text": "the machinery involved like Calvin you", "start": 3401.13, "duration": 5.76}, {"text": "refrain how often do you play with the", "start": 3403.44, "duration": 6.09}, {"text": "different set of pepper grinders for the", "start": 3406.89, "duration": 5.43}, {"text": "learn to learn models in particular for", "start": 3409.53, "duration": 5.04}, {"text": "example for all the free training API to", "start": 3412.32, "duration": 5.52}, {"text": "provide life for this API how frequently", "start": 3414.57, "duration": 8.88}, {"text": "we kind of do everything right ah it", "start": 3417.84, "duration": 7.89}, {"text": "varies depending on the domain like some", "start": 3423.45, "duration": 3.9}, {"text": "domains like vision are pretty stable", "start": 3425.73, "duration": 3.39}, {"text": "like you don't need to retrain every", "start": 3427.35, "duration": 5.88}, {"text": "every hour but other domains like for", "start": 3429.12, "duration": 5.52}, {"text": "some of our internal problems like", "start": 3433.23, "duration": 6.69}, {"text": "predicting you know you know maybe", "start": 3434.64, "duration": 6.63}, {"text": "you're trying to predict what ads are", "start": 3439.92, "duration": 4.95}, {"text": "relevant that set changes fairly rapidly", "start": 3441.27, "duration": 6.33}, {"text": "like there's a new chocolate festival on", "start": 3444.87, "duration": 4.38}, {"text": "Long Island tomorrow that wasn't there", "start": 3447.6, "duration": 3.78}, {"text": "yesterday and now you actually want to", "start": 3449.25, "duration": 4.86}, {"text": "know that that's important so some", "start": 3451.38, "duration": 4.29}, {"text": "things have a very stable distribution", "start": 3454.11, "duration": 2.16}, {"text": "some don't", "start": 3455.67, "duration": 2.16}, {"text": "it really does varies a lot depending", "start": 3456.27, "duration": 3.48}, {"text": "the problem certainly it's easier for", "start": 3457.83, "duration": 5.01}, {"text": "things like speech or vision we're just", "start": 3459.75, "duration": 4.65}, {"text": "the basic perception is what you're", "start": 3462.84, "duration": 3.18}, {"text": "trying to do and the distribution is", "start": 3464.4, "duration": 4.65}, {"text": "pretty stable and if you have a changing", "start": 3466.02, "duration": 4.77}, {"text": "distribution that just introduces lots", "start": 3469.05, "duration": 3.93}, {"text": "of annoying production issues because", "start": 3470.79, "duration": 5.1}, {"text": "now you have to retrain and you need to", "start": 3472.98, "duration": 6.45}, {"text": "sort of somehow integrate new data so", "start": 3475.89, "duration": 5.22}, {"text": "that you can learn new concepts and new", "start": 3479.43, "duration": 4.53}, {"text": "new correlations relatively quickly so", "start": 3481.11, "duration": 4.11}, {"text": "that you can then produce good", "start": 3483.96, "duration": 6.69}, {"text": "correlation good output you mentioned", "start": 3485.22, "duration": 7.08}, {"text": "sort of fast iteration being really", "start": 3490.65, "duration": 3.66}, {"text": "important for developing this stuff how", "start": 3492.3, "duration": 5.49}, {"text": "much of the process sort of now and like", "start": 3494.31, "duration": 5.82}, {"text": "the cutting edge you know neural net", "start": 3497.79, "duration": 4.32}, {"text": "development is still trial and error and", "start": 3500.13, "duration": 3.39}, {"text": "how much of it is like I'm going to", "start": 3502.11, "duration": 2.58}, {"text": "insert this and I know what's going to", "start": 3503.52, "duration": 8.07}, {"text": "happen I mean I think a lot of machine", "start": 3504.69, "duration": 9.18}, {"text": "learning research is empirical these", "start": 3511.59, "duration": 4.23}, {"text": "days right you have an idea you think", "start": 3513.87, "duration": 4.83}, {"text": "it'll work but you need to try to", "start": 3515.82, "duration": 6.21}, {"text": "implement it try it on interesting", "start": 3518.7, "duration": 6.54}, {"text": "problems explore the set of hyper", "start": 3522.03, "duration": 4.68}, {"text": "parameters or whatever that will make", "start": 3525.24, "duration": 3.45}, {"text": "the idea go from not working to", "start": 3526.71, "duration": 5.49}, {"text": "hopefully working and so it's often the", "start": 3528.69, "duration": 5.25}, {"text": "case that you need to do this kind of", "start": 3532.2, "duration": 2.089}, {"text": "impaired", "start": 3533.94, "duration": 2.809}, {"text": "stuff I mean there's some ideas that you", "start": 3534.289, "duration": 4.38}, {"text": "have a lot of intuition like oh yeah", "start": 3536.749, "duration": 4.26}, {"text": "that's definitely going to work even", "start": 3538.669, "duration": 4.02}, {"text": "beforehand because it's sort of putting", "start": 3541.009, "duration": 4.23}, {"text": "together two things that did work with a", "start": 3542.689, "duration": 4.26}, {"text": "third thing that also did work and it", "start": 3545.239, "duration": 3.24}, {"text": "seems pretty obvious that combining them", "start": 3546.949, "duration": 3.451}, {"text": "is going to work as well but other", "start": 3548.479, "duration": 6.29}, {"text": "things it's hard to build the intuition", "start": 3550.4, "duration": 4.369}, {"text": "no a while ago you guys have done some", "start": 3557.319, "duration": 4.6}, {"text": "really great work on helping visualize", "start": 3560.029, "duration": 3.99}, {"text": "what a convolutional neural network", "start": 3561.919, "duration": 3.84}, {"text": "doing image classification was doing so", "start": 3564.019, "duration": 4.111}, {"text": "like the interpretability of models seem", "start": 3565.759, "duration": 4.47}, {"text": "to be like a focus for a bit and then", "start": 3568.13, "duration": 4.049}, {"text": "there's a point where you kind of cross", "start": 3570.229, "duration": 3.48}, {"text": "that and it's like to learn to learn", "start": 3572.179, "duration": 3.39}, {"text": "stuff you just can't interpret and maybe", "start": 3573.709, "duration": 2.97}, {"text": "this is kind of what you're asking but", "start": 3575.569, "duration": 3.66}, {"text": "how important is that for delivering", "start": 3576.679, "duration": 5.461}, {"text": "production models to humans who maybe", "start": 3579.229, "duration": 4.411}, {"text": "are not machine learning experts that", "start": 3582.14, "duration": 3.27}, {"text": "need to work alongside a robot", "start": 3583.64, "duration": 4.289}, {"text": "classifier it's really important in some", "start": 3585.41, "duration": 4.199}, {"text": "domains and not important in others and", "start": 3587.929, "duration": 3.981}, {"text": "we actually have a pretty big focus I", "start": 3589.609, "duration": 5.19}, {"text": "have a much longer talk or a set of", "start": 3591.91, "duration": 6.069}, {"text": "slides I select a subset among we we", "start": 3594.799, "duration": 5.04}, {"text": "have we were doing about to work in sort", "start": 3597.979, "duration": 3.59}, {"text": "of understanding and visualizing and", "start": 3599.839, "duration": 5.48}, {"text": "gilding interpretability for models that", "start": 3601.569, "duration": 6.04}, {"text": "i didn't talk about but it is an", "start": 3605.319, "duration": 5.321}, {"text": "important area the main areas where I", "start": 3607.609, "duration": 4.41}, {"text": "think it's really important are in", "start": 3610.64, "duration": 4.709}, {"text": "health care if you tell someone you're", "start": 3612.019, "duration": 5.131}, {"text": "providing advice to a physician you say", "start": 3615.349, "duration": 3.65}, {"text": "patient needs a heart valve replacement", "start": 3617.15, "duration": 3.869}, {"text": "you know they're going to want to know", "start": 3618.999, "duration": 4.09}, {"text": "why are you saying this right and so if", "start": 3621.019, "duration": 3.93}, {"text": "you can go back and highlight a part of", "start": 3623.089, "duration": 4.23}, {"text": "a medical note that says you know a year", "start": 3624.949, "duration": 3.81}, {"text": "and a half ago a patient was complaining", "start": 3627.319, "duration": 3.12}, {"text": "about like their hearts felt like it", "start": 3628.759, "duration": 2.881}, {"text": "skipped a beat every so often or", "start": 3630.439, "duration": 6.5}, {"text": "something that's going to give much more", "start": 3631.64, "duration": 5.299}, {"text": "smooth interactions between a machine", "start": 3637.839, "duration": 4.301}, {"text": "learning system and a human and let them", "start": 3640.4, "duration": 4.139}, {"text": "kind of each do play to their strengths", "start": 3642.14, "duration": 4.619}, {"text": "whereas if you just given black box", "start": 3644.539, "duration": 4.74}, {"text": "prediction that's often not as useful in", "start": 3646.759, "duration": 4.8}, {"text": "some domains but some things like image", "start": 3649.279, "duration": 3.72}, {"text": "classification I just want the most", "start": 3651.559, "duration": 3.3}, {"text": "accurate image possible classification", "start": 3652.999, "duration": 5.3}, {"text": "puzzle yeah", "start": 3654.859, "duration": 3.44}, {"text": "coffee consumption lotion six years ago", "start": 3661.02, "duration": 7.03}, {"text": "and is there anything to be learned from", "start": 3666.19, "duration": 5.34}, {"text": "that five other areas and they have an", "start": 3668.05, "duration": 8.46}, {"text": "explosive growth feature so the thing", "start": 3671.53, "duration": 7.64}, {"text": "that caused me to start doing this as I", "start": 3676.51, "duration": 7.59}, {"text": "heard I kind of like to keep a pulse on", "start": 3679.17, "duration": 6.52}, {"text": "different areas of designs and I started", "start": 3684.1, "duration": 4.769}, {"text": "to see neural that's being successful in", "start": 3685.69, "duration": 4.8}, {"text": "some domains just by like reading", "start": 3688.869, "duration": 4.051}, {"text": "abstracts of things and I had this bug", "start": 3690.49, "duration": 3.93}, {"text": "in the back of my head from my undergrad", "start": 3692.92, "duration": 3.54}, {"text": "thesis that neural nets were actually", "start": 3694.42, "duration": 4.26}, {"text": "the right abstraction and so I kind of", "start": 3696.46, "duration": 3.96}, {"text": "heard Inklings I chatted with Andrew", "start": 3698.68, "duration": 3.57}, {"text": "Inge who was consulting at Google one", "start": 3700.42, "duration": 5.94}, {"text": "day a week and he said oh yeah no nuts", "start": 3702.25, "duration": 6.0}, {"text": "or sir I'm like what do you work out at", "start": 3706.36, "duration": 3.9}, {"text": "Stanford he's like oh no that's our kind", "start": 3708.25, "duration": 4.65}, {"text": "of interesting again i'ma go cool really", "start": 3710.26, "duration": 5.07}, {"text": "I used to do work on that and I kind of", "start": 3712.9, "duration": 5.82}, {"text": "he and I started talking and I just felt", "start": 3715.33, "duration": 6.84}, {"text": "like if the problem for neural nets was", "start": 3718.72, "duration": 5.399}, {"text": "scaled like back from my experience", "start": 3722.17, "duration": 4.949}, {"text": "where you know more compute seemed like", "start": 3724.119, "duration": 5.131}, {"text": "the right answer but wasn't then but now", "start": 3727.119, "duration": 4.5}, {"text": "we actually have a lot more data we have", "start": 3729.25, "duration": 5.34}, {"text": "much more compute in a single processor", "start": 3731.619, "duration": 5.191}, {"text": "but if we could throw lots of processors", "start": 3734.59, "duration": 5.19}, {"text": "at this problem then perhaps scale would", "start": 3736.81, "duration": 4.59}, {"text": "let us solve problems that we couldn't", "start": 3739.78, "duration": 4.14}, {"text": "before and so I kind of had this inkling", "start": 3741.4, "duration": 4.65}, {"text": "that neural nets were great abstraction", "start": 3743.92, "duration": 5.79}, {"text": "from 20 years before and felt like it", "start": 3746.05, "duration": 5.34}, {"text": "would be fun to go see if we could make", "start": 3749.71, "duration": 4.1}, {"text": "them scale", "start": 3751.39, "duration": 2.42}, {"text": "right I mean I think there's probably a", "start": 3776.88, "duration": 6.52}, {"text": "lot of algorithmic things that we're", "start": 3781.69, "duration": 3.96}, {"text": "going to need but I do think one of the", "start": 3783.4, "duration": 4.41}, {"text": "major problems and why we don't have", "start": 3785.65, "duration": 4.98}, {"text": "systems that appear to reason is because", "start": 3787.81, "duration": 4.65}, {"text": "of this problem of training neural nets", "start": 3790.63, "duration": 4.86}, {"text": "to do one thing right if you had a lot", "start": 3792.46, "duration": 4.71}, {"text": "more compute and you had a model that", "start": 3795.49, "duration": 3.42}, {"text": "could do tens of thousands of things and", "start": 3797.17, "duration": 4.71}, {"text": "you had some algorithmic constructs", "start": 3798.91, "duration": 4.86}, {"text": "where you sat there and cogitated for a", "start": 3801.88, "duration": 4.14}, {"text": "while and built sort of plausible", "start": 3803.77, "duration": 4.05}, {"text": "scenarios and explored them with compute", "start": 3806.02, "duration": 3.93}, {"text": "computation and then eventually came", "start": 3807.82, "duration": 3.87}, {"text": "back with an answer for this new thing", "start": 3809.95, "duration": 4.14}, {"text": "that might appear to be more like", "start": 3811.69, "duration": 4.2}, {"text": "reasoning because you're building on all", "start": 3814.09, "duration": 4.17}, {"text": "this other groundwork of knowledge that", "start": 3815.89, "duration": 5.16}, {"text": "you've learned from solving ten thousand", "start": 3818.26, "duration": 5.22}, {"text": "other things and I think that's what", "start": 3821.05, "duration": 5.07}, {"text": "humans do right we we learned to do a", "start": 3823.48, "duration": 5.61}, {"text": "new task or to reason through something", "start": 3826.12, "duration": 5.91}, {"text": "by building on our experience that we've", "start": 3829.09, "duration": 5.39}, {"text": "already accumulated from you know", "start": 3832.03, "duration": 5.07}, {"text": "perception and building up that kind of", "start": 3834.48, "duration": 4.96}, {"text": "low-level thing around the world but", "start": 3837.1, "duration": 4.59}, {"text": "also from you know bringing concepts", "start": 3839.44, "duration": 4.32}, {"text": "together from math and science through", "start": 3841.69, "duration": 3.96}, {"text": "our education and being able to reason", "start": 3843.76, "duration": 3.78}, {"text": "through something so I think you know a", "start": 3845.65, "duration": 3.57}, {"text": "lot of it is that we don't have these", "start": 3847.54, "duration": 4.68}, {"text": "massively multitask models being trained", "start": 3849.22, "duration": 3.88}, {"text": "today", "start": 3852.22, "duration": 3.999}, {"text": "[Music]", "start": 3853.1, "duration": 3.119}, {"text": "the knowledge store that", "start": 3856.3, "duration": 6.119}, {"text": "[Music]", "start": 3859.28, "duration": 3.139}, {"text": "right I didn't put in this talk but I", "start": 3862.66, "duration": 5.71}, {"text": "think one of the real problems that we", "start": 3866.18, "duration": 6.08}, {"text": "have is we kind of have a model and we", "start": 3868.37, "duration": 6.45}, {"text": "densely activate the entire model for", "start": 3872.26, "duration": 4.06}, {"text": "everything we do I think what we", "start": 3874.82, "duration": 4.29}, {"text": "actually want is a model that's very", "start": 3876.32, "duration": 6.51}, {"text": "very big like think you know 100 billion", "start": 3879.11, "duration": 6.78}, {"text": "trillion parameters but where for any", "start": 3882.83, "duration": 5.19}, {"text": "given thing you activate only a tiny", "start": 3885.89, "duration": 5.16}, {"text": "fraction of it 1% of it 5% of it you", "start": 3888.02, "duration": 6.21}, {"text": "know your brain works this way and that", "start": 3891.05, "duration": 5.34}, {"text": "seems like and you have to be able to", "start": 3894.23, "duration": 5.73}, {"text": "the way you store stuff is just by", "start": 3896.39, "duration": 6.47}, {"text": "having a lot of parameters", "start": 3899.96, "duration": 2.9}, {"text": "the time network nearly 10,000 sure I", "start": 3905.18, "duration": 18.97}, {"text": "mean I think memory networks are kind of", "start": 3921.48, "duration": 5.4}, {"text": "an interesting emerging area where you", "start": 3924.15, "duration": 4.62}, {"text": "have this kind of local state that you", "start": 3926.88, "duration": 5.21}, {"text": "can update and mutate in the process of", "start": 3928.77, "duration": 7.5}, {"text": "accomplishing some sort of task so far I", "start": 3932.09, "duration": 5.41}, {"text": "think those have been applied to", "start": 3936.27, "duration": 4.23}, {"text": "relatively modest size problems they may", "start": 3937.5, "duration": 4.95}, {"text": "be part of the solution part of", "start": 3940.5, "duration": 2.94}, {"text": "something that we would want like", "start": 3942.45, "duration": 4.11}, {"text": "short-term working memory as you're like", "start": 3943.44, "duration": 5.43}, {"text": "looking through a set of possible", "start": 3946.56, "duration": 6.63}, {"text": "solutions to some problem I think you", "start": 3948.87, "duration": 5.37}, {"text": "know they're definitely an interesting", "start": 3953.19, "duration": 2.16}, {"text": "area", "start": 3954.24, "duration": 5.82}, {"text": "I think combining that with you know a", "start": 3955.35, "duration": 6.51}, {"text": "model that does ten thousand things or a", "start": 3960.06, "duration": 6.29}, {"text": "million things might get us pretty far", "start": 3961.86, "duration": 4.49}, {"text": "second Simon Maybelline well I think one", "start": 3973.29, "duration": 7.66}, {"text": "of the nice things about architecture", "start": 3979.42, "duration": 3.39}, {"text": "searches actually combines really well", "start": 3980.95, "duration": 4.95}, {"text": "with machine learning researchers so if", "start": 3982.81, "duration": 5.72}, {"text": "someone comes up with a new interesting", "start": 3985.9, "duration": 5.64}, {"text": "thing you can put that in the search", "start": 3988.53, "duration": 6.19}, {"text": "space of these automated learning to", "start": 3991.54, "duration": 5.67}, {"text": "learn systems pretty easily and then all", "start": 3994.72, "duration": 4.53}, {"text": "of a sudden you now have the access to", "start": 3997.21, "duration": 4.92}, {"text": "this hybrid best of both worlds like", "start": 3999.25, "duration": 4.56}, {"text": "very primitive things but also these", "start": 4002.13, "duration": 3.6}, {"text": "hand design things that humans have come", "start": 4003.81, "duration": 6.6}, {"text": "up with the team effective and use that", "start": 4005.73, "duration": 6.81}, {"text": "as the the search day so it's not like", "start": 4010.41, "duration": 3.78}, {"text": "machine learning researchers will not", "start": 4012.54, "duration": 7.29}, {"text": "have anything to do and I think you know", "start": 4014.19, "duration": 8.67}, {"text": "there's a ton of work in figuring out", "start": 4019.83, "duration": 4.71}, {"text": "what are interesting problems where", "start": 4022.86, "duration": 3.93}, {"text": "machine learning can actually make a", "start": 4024.54, "duration": 4.02}, {"text": "difference and which ones are worth", "start": 4026.79, "duration": 6.32}, {"text": "solving and how do we solve them so", "start": 4028.56, "duration": 6.63}, {"text": "maybe good time for this question what", "start": 4033.11, "duration": 3.61}, {"text": "what's in your opinion what's like the", "start": 4035.19, "duration": 2.82}, {"text": "coolest thing neural nets are being", "start": 4036.72, "duration": 5.85}, {"text": "applied to you right now I'm really", "start": 4038.01, "duration": 6.81}, {"text": "excited about healthcare I think the", "start": 4042.57, "duration": 6.63}, {"text": "ability of neural nets to ingest a lot", "start": 4044.82, "duration": 7.53}, {"text": "of data and then make sort of", "start": 4049.2, "duration": 5.96}, {"text": "interesting predictions in a smooth way", "start": 4052.35, "duration": 5.07}, {"text": "that you can take a patient in a", "start": 4055.16, "duration": 4.9}, {"text": "particular state and say okay here are", "start": 4057.42, "duration": 4.71}, {"text": "the five most likely diagnosis for the", "start": 4060.06, "duration": 4.89}, {"text": "station because you know I've seen you", "start": 4062.13, "duration": 4.83}, {"text": "know a million other patients and I I", "start": 4064.95, "duration": 5.22}, {"text": "know the 17 you need to have similar", "start": 4066.96, "duration": 5.28}, {"text": "conditions you know I think that's", "start": 4070.17, "duration": 3.78}, {"text": "that's one that we'll have a really big", "start": 4072.24, "duration": 4.38}, {"text": "societal impact it's you know fraught", "start": 4073.95, "duration": 5.28}, {"text": "with lots of role lot issues because", "start": 4076.62, "duration": 4.05}, {"text": "there's a heavily regulated environment", "start": 4079.23, "duration": 3.15}, {"text": "there's all kinds of privacy issues but", "start": 4080.67, "duration": 4.41}, {"text": "ultimately I think making better", "start": 4082.38, "duration": 5.19}, {"text": "healthcare decisions is going to be", "start": 4085.08, "duration": 6.75}, {"text": "pretty big the coolest things you know I", "start": 4087.57, "duration": 6.42}, {"text": "really like all the art generation kind", "start": 4091.83, "duration": 5.489}, {"text": "of wings those are fun the ability of", "start": 4093.99, "duration": 5.22}, {"text": "neural nets to write a sentence about an", "start": 4097.319, "duration": 5.011}, {"text": "image you know I I was kind of surprised", "start": 4099.21, "duration": 4.8}, {"text": "that happened that early I would have", "start": 4102.33, "duration": 2.11}, {"text": "said", "start": 4104.01, "duration": 2.499}, {"text": "you know before that work some of which", "start": 4104.44, "duration": 3.81}, {"text": "was done in our group I would have said", "start": 4106.509, "duration": 3.571}, {"text": "I don't you know we're good at saying", "start": 4108.25, "duration": 3.239}, {"text": "that the lion I don't think we can say", "start": 4110.08, "duration": 4.02}, {"text": "that's the lion sleeping on a rock with", "start": 4111.489, "duration": 4.191}, {"text": "a pretty yellow Ming or whatever it is", "start": 4114.1, "duration": 5.33}, {"text": "and that that's pretty cool", "start": 4115.68, "duration": 7.29}, {"text": "okay okay anywhere thank you", "start": 4119.43, "duration": 8.849}, {"text": "[Applause]", "start": 4122.97, "duration": 5.309}, {"text": "you", "start": 4133.16, "duration": 2.06}]